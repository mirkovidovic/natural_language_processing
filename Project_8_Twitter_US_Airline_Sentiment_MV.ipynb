{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import the libraries, load dataset, print shape of data, data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "dataset=pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing first 5 rows of data\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting unique values of ariline_sentiment to acquire classes of target variable\n",
    "dataset.airline_sentiment.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is composed of 15 columns and 14640 rows. It means there are 14640 tweets to be used to train and test model for sentiment extraction.\n",
    "There are 3 classes of target variable (airline_sentiment) - neutral, positive and negative. This information will be usefull once the training of the model is to be done. \n",
    "Following code tries to find portion of those classes in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.14071038251366"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percentage of of positive sentiment\n",
    "100*dataset[dataset['airline_sentiment']=='positive'].shape[0]/dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.69125683060109"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percentage of of negative sentiment\n",
    "100*dataset[dataset['airline_sentiment']=='negative'].shape[0]/dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.168032786885245"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percentage of of negative sentiment\n",
    "100*dataset[dataset['airline_sentiment']=='neutral'].shape[0]/dataset.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suprisingly, most of the tweets are negative ones - having share of more than 62%. It could be said target variable is not highly imbalanced, since there is no class that is represented in more than 90% of data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                        False\n",
       "airline_sentiment               False\n",
       "airline_sentiment_confidence    False\n",
       "negativereason                   True\n",
       "negativereason_confidence        True\n",
       "airline                         False\n",
       "airline_sentiment_gold           True\n",
       "name                            False\n",
       "negativereason_gold              True\n",
       "retweet_count                   False\n",
       "text                            False\n",
       "tweet_coord                      True\n",
       "tweet_created                   False\n",
       "tweet_location                   True\n",
       "user_timezone                    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if there are null values in dataset\n",
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some columns with null values, however, columns of our interest (airline sentiment and text) have no null values. Null values in e.g. column negativeReason are result of non applicability in case the sentiment is positive or neutral. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Understand of data-columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Drop all other columns except “text” and “airline_sentiment”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of dropping columns, dataset is only reshaped by using only two columns of further interest. That approach is used becuase there are only two columns to be used out of 15 columns. The result is the same as 13 columns have been dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning only two out of 15 columns of dataset to dataset\n",
    "dataset=dataset[[ 'text','airline_sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Check the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 2)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset is composed on 14640 rows (cases) and 2 columns (text and target variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Print the first 5 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0                @VirginAmerica What @dhepburn said.           neutral\n",
       "1  @VirginAmerica plus you've added commercials t...          positive\n",
       "2  @VirginAmerica I didn't today... Must mean I n...           neutral\n",
       "3  @VirginAmerica it's really aggressive to blast...          negative\n",
       "4  @VirginAmerica and it's a really big bad thing...          negative"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text pre-processing: Data preparation.\n",
    "#### NOTE:- Each text pre-processing steps should be mentioned in the notebook separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task is to do text pre-processing to prepare raw text to the text which will be vecotrized. The approach used is to develop functions for each pre processing step. At the end, final fiunction is developed which combine all of the functions developed for each step in one consecutive order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Html tag removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which takes text with html tags and returns text without it.\n",
    "\n",
    "#soup=BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "def html_remover(text_with_html):\n",
    "    #applying get_text() function of BeautifulSoup class\n",
    "    text_no_html = BeautifulSoup(text_with_html,\"html.parser\").get_text()\n",
    "    return (text_no_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which tokenize text and returns list of tokens\n",
    "def tokenization(text_to_tokenize):\n",
    "    #instancing ToktokTokenizer object\n",
    "    tokenizer=ToktokTokenizer()\n",
    "    #applying tokenize() function of ToktokTokenizer object instance\n",
    "    tokens=tokenizer.tokenize(text_to_tokenize)\n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Remove the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which returns text without numbers\n",
    "def removal_number(text_with_numbers):\n",
    "    #pattern is created in a form \"[0,1,2,3,4,5,6,7,8,9]\"\n",
    "    pattern=r'[0-9]'\n",
    "    #pattern is substitued with null value; in other words, whenever there is a digit identified, it is subsituted with nothing\n",
    "    text_without_numbers=re.sub(pattern,'',text_with_numbers)\n",
    "    return(text_without_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Removal of Special Characters and Punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which removes special characters by preserving only characters a-zA-Z and space\n",
    "def removal_special_characters(text_with_special_char):\n",
    "    #pattern is created in a form \"not [a-zA-Z and space]\"\n",
    "    pattern=r'[^a-zA-Z\\s]'\n",
    "    #pattern is subsituted with nothing; \n",
    "    #in effect, whenever a character that does not belongs to small or capital letter \n",
    "    #or a space character is encountered, it is subsituted with nothing\n",
    "    text_without_special_char=re.sub(pattern,'', text_with_special_char)\n",
    "    return(text_without_special_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Conversion to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that returns text with lowercase only\n",
    "def to_lower_case(text_with_upper_case):\n",
    "    text_lower_case_only=text_with_upper_case.lower()\n",
    "    return(text_lower_case_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f. Lemmatize or stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instance of WordNetLemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#function to lemmatize word\n",
    "def nltk_lemmatize_word(word):\n",
    "    #applying lemmatize function of WordNetLemmatizer() object\n",
    "    return lemmatizer.lemmatize(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g. Join the words in the list to convert back to text string in the data frame. (So that each row contains the data in text format.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which recieve list of words and joins them into text\n",
    "def join_words(words_to_join):\n",
    "    return (\" \".join(words_to_join))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which combineds all of the steps above\n",
    "def preprocess_text(raw_text):\n",
    "    #removal of html\n",
    "    no_html_text=html_remover(raw_text)\n",
    "    \n",
    "    #tokenization\n",
    "    tokens=tokenization(no_html_text)\n",
    "    #creating empty list to store preprocessed tokens\n",
    "    preprocessed_tokens=[]\n",
    "    #loop to run through all tokens of the raw_text (which are result of tokenization step)\n",
    "    for i in tokens:\n",
    "        #in this loop all tasks are performed on single token (word)\n",
    "        \n",
    "        #removal of special characters\n",
    "        spec_char_removed=removal_special_characters(i)\n",
    "        #removal of upper case\n",
    "        lower_case=to_lower_case(spec_char_removed)\n",
    "        #lemmatization of word\n",
    "        lemmatized_word=nltk_lemmatize_word(lower_case)\n",
    "        \n",
    "        #storing all results performed on individual tokens in one list \n",
    "        preprocessed_tokens.append(lemmatized_word)\n",
    "             \n",
    "    \n",
    "    #joining the words(preprocessed tokens) into one text and returning the result\n",
    "    return(join_words(preprocessed_tokens))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verfication of the preprocess_text()function on a single text entry\n",
    "preproc_tok=preprocess_text(dataset['text'][50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginamerica is flight  on it  s way  wa supposed to take off  minute ago website still show  on time  not  in flight   thanks '"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the result of preprocess_text()function on a single text entry\n",
    "preproc_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@VirginAmerica Is flight 769 on it\\'s way? Was supposed to take off 30 minutes ago. Website still shows \"On Time\" not \"In Flight\". Thanks.'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing original text for comparison\n",
    "dataset['text'][50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess_text function removed all special characters, numbers, capital letters, and lemmatized words (e.g. shows--> show, minutes-->minute), however, there still opportunity to further preprocess text (e.g. contractions have not been converted (e.g. it's) or stop words have not been removed), however, task was clear on required preprocessed steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to apply preprocess_text() function (and inherently all text preprocessing steps) on dataset. It is done in a loop where each element of dataset['text'] dataframe column have been passed to the function and result is stored on same place of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeting index to 0 \n",
    "i=0\n",
    "#looping through all the elements of dataset['text'] column\n",
    "for text in dataset['text']:\n",
    "    dataset['text'].iloc[i]=preprocess_text(text)\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginamerica is flight  on it  s way  wa supposed to take off  minute ago website still show  on time  not  in flight   thanks '"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verifying if the preprocess steps were performed correctly on a snigle entry\n",
    "dataset['text'].iloc[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## h. Print the first 5 rows of data after pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virginamerica what dhepburn said</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>virginamerica plus you  ve added commercial to...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>virginamerica i didn  t today  must mean i nee...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>virginamerica it  s really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica and it  s a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0                  virginamerica what dhepburn said            neutral\n",
       "1  virginamerica plus you  ve added commercial to...          positive\n",
       "2  virginamerica i didn  t today  must mean i nee...           neutral\n",
       "3  virginamerica it  s really aggressive to blast...          negative\n",
       "4  virginamerica and it  s a really big bad thing...          negative"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Vectorization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that target variable is composed of three possible classes. There are to possible ways to represetn such classes in numerical form - to perform one hot encoding of target variable, or to perform label encoding. \n",
    "\n",
    "In case of one hot encoding, target would be composed of three columns (or two if one of the varibles would be droped(e.g. if sentiment is not negative or neutral, then it is positive and there is no reason to retain such variable ; it is completly defined by other two)). Having three(or two target variables) might lead to missclassification in case all of the targets are classified as 0 (e.g. all three classes resulted in 0 value - in effect it would mean there was no class identified for such case).\n",
    "\n",
    "In case of label encoding, labels would be given to each sentiment class (e.g. negative - 0, neutral - 1, positive - 2). Problem with label encoding is it is hard to establish values of labels (e.g. it could be the other way around for given example of labels), however target would remain as one vairable (one column). \n",
    "\n",
    "Both approaches will be used, since both have some advantages and disadvantages. \n",
    "\n",
    "In addition to above, dataset needs to be splitted into train and test data before vectorization is applied. The reason for this is to prevent dataleaks between train and test data. Data leak might happen if vocabulary of vectorizer is generated base don whole dataset, instead of train data only. If such vocabulary is generated only on train data, then, once the transform function of vectorizer is applied on test data, only vocabulary of train data will be used, hence simulating real unseen data (some new words might be present in test data that are not part of train data vocabulary).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating dummy_variable (one hot encoding) from target variable\n",
    "dataset_dummy_target=pd.get_dummies(dataset, drop_first=False, prefix='', prefix_sep='', columns=['airline_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virginamerica what dhepburn said</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>virginamerica plus you  ve added commercial to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>virginamerica i didn  t today  must mean i nee...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>virginamerica it  s really aggressive to blast...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica and it  s a really big bad thing...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  negative  neutral  \\\n",
       "0                  virginamerica what dhepburn said          0        1   \n",
       "1  virginamerica plus you  ve added commercial to...         0        0   \n",
       "2  virginamerica i didn  t today  must mean i nee...         0        1   \n",
       "3  virginamerica it  s really aggressive to blast...         1        0   \n",
       "4  virginamerica and it  s a really big bad thing...         1        0   \n",
       "\n",
       "   positive  \n",
       "0         0  \n",
       "1         1  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verifying the result of previous step\n",
    "dataset_dummy_target.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating mapping dictionary\n",
    "labels_dict={'negative': 0, 'neutral': 1, 'positive': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating int_label list where labels are stored in correspondence to airline sentiment\n",
    "int_labels=[]\n",
    "for value in dataset['airline_sentiment']:\n",
    "    #extracting the value of key in labels_dict dictionary\n",
    "    int_labels.append(labels_dict[value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting index for label_necoded_target_series\n",
    "index=dataset.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating pandas series to be concatenated to dataset dataframe\n",
    "label_encoded_target_series=pd.Series(data=int_labels, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating new dataset by concatenation of dataset and series generated in step above\n",
    "dataset_label_encoded_target=pd.concat([dataset, label_encoded_target_series], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virginamerica what dhepburn said</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>virginamerica plus you  ve added commercial to...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>virginamerica i didn  t today  must mean i nee...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>virginamerica it  s really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica and it  s a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>americanair thank you we got on a different fl...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>americanair leaving over  minute late flight n...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>americanair please bring american airline to b...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>americanair you have my money  you change my f...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>americanair we have  ppl so we need  know how ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment  0\n",
       "0                      virginamerica what dhepburn said            neutral  1\n",
       "1      virginamerica plus you  ve added commercial to...          positive  2\n",
       "2      virginamerica i didn  t today  must mean i nee...           neutral  1\n",
       "3      virginamerica it  s really aggressive to blast...          negative  0\n",
       "4      virginamerica and it  s a really big bad thing...          negative  0\n",
       "...                                                  ...               ... ..\n",
       "14635  americanair thank you we got on a different fl...          positive  2\n",
       "14636  americanair leaving over  minute late flight n...          negative  0\n",
       "14637  americanair please bring american airline to b...           neutral  1\n",
       "14638  americanair you have my money  you change my f...          negative  0\n",
       "14639  americanair we have  ppl so we need  know how ...           neutral  1\n",
       "\n",
       "[14640 rows x 3 columns]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verifying previous steps\n",
    "dataset_label_encoded_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting dataset into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting dataset where target variable is tranformed into dummy variables\n",
    "x_train_d, x_test_d, y_train_d, y_test_d=train_test_split(dataset_dummy_target['text'], dataset_dummy_target[['negative','neutral', 'positive']], test_size=0.3, stratify=dataset_dummy_target[['negative','neutral', 'positive']], random_state=7)\n",
    "\n",
    "#splitting dataset where target is label encoded\n",
    "x_train_l, x_test_l, y_train_l, y_test_l=train_test_split(dataset_label_encoded_target['text'], dataset_label_encoded_target[0], test_size=0.3, stratify=dataset_label_encoded_target[0], random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapes of trainning datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10248,)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10248, 3)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10248,)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10248,)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_l.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First few rows of y_test_d and y_test_l:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10586</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8957</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8784</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       negative  neutral  positive\n",
       "9982          1        0         0\n",
       "7868          0        1         0\n",
       "10586         1        0         0\n",
       "8957          0        1         0\n",
       "8784          1        0         0"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_d.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8651     0\n",
       "11637    0\n",
       "7739     1\n",
       "1245     1\n",
       "9256     1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_l.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating vectors\n",
    "\n",
    "Both CountVectorizer and TfIdfVectorizer will be applied on two sets of trainning and test data - once for one-hot-encoded and once for label encoded target variables. Even though this action is applied only on independant variables and does not include target variable, it is safer to do this step on both becuase of train test split action that was performed beforehand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Use CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for target dummy_variable \n",
    "\n",
    "#creating vectorizer - C in name means count, d at the end means dummy target variable\n",
    "C_vectorizer_d=CountVectorizer()\n",
    "\n",
    "#vectorizer is fitted with trainning data\n",
    "C_vectorizer_d.fit(x_train_d)\n",
    "\n",
    "#transform is applied on both, trainning and test data\n",
    "x_train_features_countV_d=C_vectorizer_d.transform(x_train_d)\n",
    "x_test_features_countV_d=C_vectorizer_d.transform(x_test_d)\n",
    "\n",
    "x_train_features_countV_d=x_train_features_countV_d.toarray()\n",
    "x_test_features_countV_d=x_test_features_countV_d.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for target label encoded\n",
    "\n",
    "#creating vectorizer - C in name means count, l at the end means label encoded target variable\n",
    "C_vectorizer_l=CountVectorizer()\n",
    "\n",
    "#vectorizer is fitted with trainning data\n",
    "C_vectorizer_l.fit(x_train_l)\n",
    "\n",
    "#transform is applied on both, trainning and test data\n",
    "x_train_features_countV_l=C_vectorizer_l.transform(x_train_l)\n",
    "x_test_features_countV_l=C_vectorizer_l.transform(x_test_l)\n",
    "\n",
    "x_train_features_countV_l=x_train_features_countV_l.toarray()\n",
    "x_test_features_countV_l=x_test_features_countV_l.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'united': 9869,\n",
       " 'flt': 3277,\n",
       " 'cancelled': 1266,\n",
       " 'flightled': 3240,\n",
       " 'and': 368,\n",
       " 'get': 3569,\n",
       " 'email': 2721,\n",
       " 'am': 317,\n",
       " 'what': 10301,\n",
       " 'happened': 3829,\n",
       " 'to': 9537,\n",
       " 'courtesy': 1920,\n",
       " 'phn': 7246,\n",
       " 'call': 1246,\n",
       " 'had': 3789,\n",
       " 'book': 1001,\n",
       " 'diff': 2346,\n",
       " 'airline': 223,\n",
       " 'amp': 356,\n",
       " 'city': 1533,\n",
       " 'delayed': 2194,\n",
       " 'because': 818,\n",
       " 'of': 6824,\n",
       " 'maintenance': 6037,\n",
       " 'that': 9374,\n",
       " 'fixed': 3191,\n",
       " 'but': 1200,\n",
       " 'can': 1262,\n",
       " 'board': 979,\n",
       " 'flight': 3217,\n",
       " 'crew': 1969,\n",
       " 'didn': 2338,\n",
       " 'stay': 8958,\n",
       " 'in': 5088,\n",
       " 'boarding': 981,\n",
       " 'area': 506,\n",
       " 'fail': 3024,\n",
       " 'my': 6479,\n",
       " 'dad': 2059,\n",
       " 'booked': 1002,\n",
       " 'through': 9453,\n",
       " 'orbitz': 6930,\n",
       " 'due': 2602,\n",
       " 'weather': 10239,\n",
       " 'he': 3883,\n",
       " 'make': 6042,\n",
       " 'it': 5323,\n",
       " 'the': 9377,\n",
       " 'airport': 233,\n",
       " 'you': 10565,\n",
       " 'help': 3926,\n",
       " 'him': 3984,\n",
       " 'read': 7755,\n",
       " 'bio': 913,\n",
       " 'see': 8407,\n",
       " 'who': 10337,\n",
       " 'work': 10436,\n",
       " 'with': 10391,\n",
       " 'have': 3868,\n",
       " 'never': 6568,\n",
       " 'encountered': 2760,\n",
       " 'this': 9427,\n",
       " 'your': 10573,\n",
       " 'before': 829,\n",
       " 'disappointed': 2386,\n",
       " 'is': 5303,\n",
       " 'an': 363,\n",
       " 'understatement': 9839,\n",
       " 'jetblue': 5416,\n",
       " 'our': 6977,\n",
       " 'fleet': 3208,\n",
       " 'on': 6871,\n",
       " 'fleek': 3207,\n",
       " 'httptcomwsgolgo': 4571,\n",
       " 'thanks': 9363,\n",
       " 'love': 5941,\n",
       " 'report': 7971,\n",
       " 'how': 4110,\n",
       " 'horrible': 4070,\n",
       " 'team': 9296,\n",
       " 'let': 5758,\n",
       " 'worse': 10454,\n",
       " 'they': 9409,\n",
       " 'seat': 8384,\n",
       " 'out': 6981,\n",
       " 'all': 275,\n",
       " 'snack': 8736,\n",
       " 'do': 2485,\n",
       " 'any': 425,\n",
       " 'lie': 5788,\n",
       " 'flat': 3201,\n",
       " 'seating': 8390,\n",
       " 'from': 3449,\n",
       " 'stl': 8996,\n",
       " 'pdx': 7165,\n",
       " 'around': 522,\n",
       " 'date': 2103,\n",
       " 'march': 6082,\n",
       " 'wa': 10147,\n",
       " 'not': 6723,\n",
       " 'allowed': 288,\n",
       " 'drop': 2580,\n",
       " 'bag': 730,\n",
       " 'off': 6825,\n",
       " 'for': 3351,\n",
       " 'running': 8222,\n",
       " 'min': 6286,\n",
       " 'late': 5674,\n",
       " 'turn': 9736,\n",
       " 'left': 5738,\n",
       " 'over': 7004,\n",
       " 'hour': 4096,\n",
       " 'americanair': 334,\n",
       " 'trying': 9712,\n",
       " 'change': 1402,\n",
       " 'time': 9490,\n",
       " 'already': 299,\n",
       " 'purchased': 7638,\n",
       " 'told': 9551,\n",
       " 'pay': 7153,\n",
       " 'fee': 3103,\n",
       " 'ridiculous': 8110,\n",
       " 'virginamerica': 10103,\n",
       " 'guy': 3781,\n",
       " 'know': 5603,\n",
       " 'checkin': 1445,\n",
       " 'link': 5822,\n",
       " 'are': 505,\n",
       " 'broken': 1112,\n",
       " 'httptconpxbobmr': 4597,\n",
       " 'we': 10233,\n",
       " 'll': 5856,\n",
       " 'luggage': 5983,\n",
       " 'after': 172,\n",
       " 'flying': 3295,\n",
       " 'saturday': 8301,\n",
       " 'where': 10318,\n",
       " 'expecting': 2959,\n",
       " 'ice': 5008,\n",
       " 'snow': 8747,\n",
       " 'when': 10316,\n",
       " 'should': 8564,\n",
       " 'start': 8938,\n",
       " 'looking': 5911,\n",
       " 'travel': 9642,\n",
       " 'waiver': 10165,\n",
       " 'southwestair': 8823,\n",
       " 'number': 6776,\n",
       " 'use': 9990,\n",
       " 'outside': 6997,\n",
       " 'thx': 9465,\n",
       " 'yes': 10553,\n",
       " 'waited': 10154,\n",
       " 'line': 5817,\n",
       " 'almost': 295,\n",
       " 'so': 8758,\n",
       " 'some': 8782,\n",
       " 'passenger': 7114,\n",
       " 'just': 5504,\n",
       " 'wanting': 10187,\n",
       " 'wait': 10152,\n",
       " 'past': 7124,\n",
       " 'ask': 553,\n",
       " 'slc': 8682,\n",
       " 'checkinbag': 1446,\n",
       " 'if': 5033,\n",
       " 'found': 3388,\n",
       " 'dark': 2099,\n",
       " 'blueblackish': 969,\n",
       " 'fit': 3187,\n",
       " 'bit': 921,\n",
       " 'flex': 3210,\n",
       " 'would': 10473,\n",
       " 've': 10048,\n",
       " 'lost': 5925,\n",
       " 'there': 9398,\n",
       " 'pm': 7363,\n",
       " 'mt': 6447,\n",
       " 'stuffy': 9069,\n",
       " 'plane': 7309,\n",
       " 'until': 9933,\n",
       " 'could': 1900,\n",
       " 'then': 9393,\n",
       " 'more': 6401,\n",
       " 'hr': 4117,\n",
       " 'their': 9386,\n",
       " 'americanairlines': 337,\n",
       " 'respond': 8030,\n",
       " 'tweet': 9747,\n",
       " 'dm': 2473,\n",
       " 'really': 7770,\n",
       " 'sad': 8241,\n",
       " 'feeling': 3107,\n",
       " 'be': 801,\n",
       " 'ignored': 5040,\n",
       " 'worst': 10455,\n",
       " 'don': 2507,\n",
       " 'me': 6164,\n",
       " 'hold': 4012,\n",
       " 'enter': 2795,\n",
       " 'callback': 1247,\n",
       " 'middle': 6254,\n",
       " 'night': 6615,\n",
       " 'will': 10363,\n",
       " 'third': 9424,\n",
       " 'been': 826,\n",
       " 'called': 1249,\n",
       " 'by': 1218,\n",
       " 'hung': 4979,\n",
       " 'anyone': 429,\n",
       " 'speaks': 8846,\n",
       " 'now': 6759,\n",
       " 'captain': 1290,\n",
       " 'apologize': 446,\n",
       " 'delay': 2193,\n",
       " 'company': 1714,\n",
       " 'open': 6909,\n",
       " 'gate': 3537,\n",
       " 'glance': 3612,\n",
       " 'starboard': 8934,\n",
       " 'side': 8599,\n",
       " 'ua': 9780,\n",
       " 'take': 9246,\n",
       " 'without': 10394,\n",
       " 'missing': 6330,\n",
       " 'galley': 3525,\n",
       " 'cart': 1324,\n",
       " 'no': 6636,\n",
       " 'one': 6878,\n",
       " 'find': 3161,\n",
       " 'pax': 7151,\n",
       " 'seated': 8389,\n",
       " 'last': 5667,\n",
       " 'bereavement': 865,\n",
       " 'discount': 2403,\n",
       " 'airfare': 222,\n",
       " 'grandfather': 3697,\n",
       " 'passed': 7112,\n",
       " 'need': 6536,\n",
       " 'attend': 608,\n",
       " 'his': 3995,\n",
       " 'funeral': 3501,\n",
       " 'week': 10253,\n",
       " 'usairways': 9978,\n",
       " 'issue': 5316,\n",
       " 'still': 8987,\n",
       " 'resolved': 8023,\n",
       " 'hope': 4058,\n",
       " 'every': 2890,\n",
       " 'minute': 6302,\n",
       " 'talk': 9257,\n",
       " 'system': 9229,\n",
       " 'fucking': 3477,\n",
       " 'joke': 5465,\n",
       " 'kidding': 5569,\n",
       " 'answering': 410,\n",
       " 'reserv': 8014,\n",
       " 'high': 3969,\n",
       " 'volume': 10127,\n",
       " 'even': 2880,\n",
       " 'option': 6926,\n",
       " 'brutal': 1130,\n",
       " 'reservation': 8015,\n",
       " 'follow': 3336,\n",
       " 'detail': 2304,\n",
       " 'mht': 6241,\n",
       " 'fun': 3494,\n",
       " 'kid': 5568,\n",
       " 'grandkids': 3698,\n",
       " 'them': 9388,\n",
       " 'jack': 5357,\n",
       " 'say': 8317,\n",
       " 'hi': 3963,\n",
       " 'httptcobhooiytzq': 4209,\n",
       " 'great': 3711,\n",
       " 'doe': 2491,\n",
       " 'im': 5056,\n",
       " 'reward': 8094,\n",
       " 'ticket': 9470,\n",
       " 'world': 10446,\n",
       " 'partner': 7103,\n",
       " 'automated': 644,\n",
       " 'wont': 10426,\n",
       " 'job': 5458,\n",
       " 'aa': 0,\n",
       " 'employee': 2751,\n",
       " 'were': 10279,\n",
       " 'rude': 8206,\n",
       " 'unwilling': 9941,\n",
       " 'mile': 6273,\n",
       " 'rotten': 8183,\n",
       " 'cherry': 1462,\n",
       " 'top': 9576,\n",
       " 'dog': 2495,\n",
       " 'shit': 8543,\n",
       " 'sunday': 9123,\n",
       " 'nocareforcustomers': 6645,\n",
       " 'got': 3674,\n",
       " 'known': 5607,\n",
       " 'traveler': 9644,\n",
       " 'like': 5804,\n",
       " 'add': 119,\n",
       " 'best': 868,\n",
       " 'heading': 3888,\n",
       " 'milan': 6271,\n",
       " 'wednesday': 10251,\n",
       " 'big': 900,\n",
       " 'family': 3052,\n",
       " 'at': 587,\n",
       " 'point': 7371,\n",
       " 'made': 6017,\n",
       " 'home': 4026,\n",
       " 'own': 7037,\n",
       " 'httptcoltxjkbo': 4536,\n",
       " 'dead': 2137,\n",
       " 'yet': 10559,\n",
       " 'dealing': 2142,\n",
       " 'since': 8621,\n",
       " 'wouldve': 10479,\n",
       " 'least': 5729,\n",
       " 'liked': 5806,\n",
       " 'ella': 2711,\n",
       " 'perform': 7197,\n",
       " 'lol': 5894,\n",
       " 'reach': 7748,\n",
       " 'american': 333,\n",
       " 'evening': 2881,\n",
       " 'customer': 2029,\n",
       " 'service': 8465,\n",
       " 'ever': 2888,\n",
       " 'also': 303,\n",
       " 'southwest': 8822,\n",
       " 'other': 6966,\n",
       " 'special': 8848,\n",
       " 'view': 10090,\n",
       " 'downtown': 2547,\n",
       " 'los': 5919,\n",
       " 'angeles': 380,\n",
       " 'hollywood': 4023,\n",
       " 'sign': 8603,\n",
       " 'beyond': 887,\n",
       " 'rain': 7704,\n",
       " 'mountain': 6420,\n",
       " 'httptcodwnfibtr': 4290,\n",
       " 'please': 7339,\n",
       " 'she': 8527,\n",
       " 'went': 10277,\n",
       " 'above': 40,\n",
       " 'her': 3947,\n",
       " 'priority': 7526,\n",
       " 'hiltonworldwide': 3983,\n",
       " 'caravannyc': 1296,\n",
       " 'maysvillenyc': 6136,\n",
       " 'go': 3628,\n",
       " 'join': 5463,\n",
       " 'first': 3181,\n",
       " 'trip': 9678,\n",
       " 'back': 702,\n",
       " 'nyc': 6787,\n",
       " 'tourist': 9598,\n",
       " 'httptcoegaejtrglb': 4303,\n",
       " 'ny': 6786,\n",
       " 'scheduled': 8344,\n",
       " 'leave': 5733,\n",
       " 'than': 9355,\n",
       " 'checking': 1447,\n",
       " 'huge': 4968,\n",
       " 'give': 3602,\n",
       " 'answer': 408,\n",
       " 'why': 10345,\n",
       " 'long': 5900,\n",
       " 'compensate': 1722,\n",
       " 'lima': 5811,\n",
       " 'cuzco': 2048,\n",
       " 'hello': 3924,\n",
       " 'swa': 9176,\n",
       " 'poc': 7369,\n",
       " 'partnership': 7104,\n",
       " 'nonprofit': 6686,\n",
       " 'organization': 6948,\n",
       " 'bwi': 1212,\n",
       " 'address': 125,\n",
       " 'put': 7649,\n",
       " 'next': 6596,\n",
       " 'available': 652,\n",
       " 'ohare': 6843,\n",
       " 'today': 9540,\n",
       " 'unpleasant': 9908,\n",
       " 'experience': 2968,\n",
       " 'life': 5791,\n",
       " 'might': 6265,\n",
       " 'till': 9487,\n",
       " 'tomorrow': 9560,\n",
       " 'insane': 5200,\n",
       " 'wish': 10390,\n",
       " 'notified': 6743,\n",
       " 'flyus': 3319,\n",
       " 'ripoff': 8122,\n",
       " 'rebooked': 7787,\n",
       " 'whole': 10340,\n",
       " 'day': 2109,\n",
       " 'vacation': 10024,\n",
       " 'these': 9402,\n",
       " 'fare': 3064,\n",
       " 'notch': 6726,\n",
       " 'wonder': 10419,\n",
       " 'cabin': 1228,\n",
       " 'filthy': 3153,\n",
       " 'badservice': 726,\n",
       " 'extend': 2989,\n",
       " 'rtn': 8200,\n",
       " 'nd': 6528,\n",
       " 'dropped': 2582,\n",
       " 'noworse': 6765,\n",
       " 'badcustomerservice': 719,\n",
       " 'according': 75,\n",
       " 'jfk': 5435,\n",
       " 'plenty': 7351,\n",
       " 'landing': 5655,\n",
       " 'problem': 7539,\n",
       " 'thank': 9356,\n",
       " 'cincyjust': 1520,\n",
       " 'landedyou': 5654,\n",
       " 'frequent': 3426,\n",
       " 'flyer': 3290,\n",
       " 'account': 77,\n",
       " 'incredibly': 5133,\n",
       " 'frustrating': 3463,\n",
       " 'anytime': 434,\n",
       " 'sugafly': 9105,\n",
       " 'airway': 244,\n",
       " 'qantas': 7655,\n",
       " 'notification': 6742,\n",
       " 'coming': 1687,\n",
       " 'sw': 9175,\n",
       " 'rsw': 8197,\n",
       " 'mke': 6345,\n",
       " 'update': 9946,\n",
       " 'baggage': 732,\n",
       " 'claim': 1539,\n",
       " 'incompetence': 5117,\n",
       " 'overwhelming': 7031,\n",
       " 'reply': 7968,\n",
       " 'share': 8520,\n",
       " 'thought': 9439,\n",
       " 'greater': 3713,\n",
       " 'via': 10081,\n",
       " 'web': 10245,\n",
       " 'form': 3371,\n",
       " 'taking': 9253,\n",
       " 'providing': 7606,\n",
       " 'about': 39,\n",
       " 'which': 10327,\n",
       " 'httptcoambsig': 4169,\n",
       " 'guideline': 3776,\n",
       " 'xx': 10528,\n",
       " 'taller': 9260,\n",
       " 'gonna': 3651,\n",
       " 'going': 3637,\n",
       " 'weekend': 10255,\n",
       " 'friend': 3437,\n",
       " 'birthday': 919,\n",
       " 'reflight': 7861,\n",
       " 'booking': 1003,\n",
       " 'arrive': 528,\n",
       " 'ha': 3785,\n",
       " 'plan': 7307,\n",
       " 'dollar': 2502,\n",
       " 'laxlas': 5699,\n",
       " 'here': 3952,\n",
       " 'few': 3124,\n",
       " 'month': 6390,\n",
       " 'ago': 193,\n",
       " 'none': 6679,\n",
       " 'weird': 10263,\n",
       " 'club': 1602,\n",
       " 'busiest': 1190,\n",
       " 'apology': 450,\n",
       " 'fix': 3190,\n",
       " 'competent': 1728,\n",
       " 'manner': 6075,\n",
       " 'rhonda': 8096,\n",
       " 'atlanta': 593,\n",
       " 'redeemed': 7833,\n",
       " 'straightened': 9023,\n",
       " 'did': 2337,\n",
       " 'expect': 2956,\n",
       " 'response': 8034,\n",
       " 'fiscal': 3185,\n",
       " 'year': 10543,\n",
       " 'calendar': 1242,\n",
       " 'new': 6577,\n",
       " 'schedule': 8342,\n",
       " 'nonstop': 6690,\n",
       " 'phl': 7237,\n",
       " 'fll': 3267,\n",
       " 'or': 6927,\n",
       " 'pbi': 7161,\n",
       " 'free': 3416,\n",
       " 'move': 6423,\n",
       " 'between': 884,\n",
       " 'those': 9437,\n",
       " 'shouldn': 8571,\n",
       " 'longer': 5904,\n",
       " 'itself': 5341,\n",
       " 'runway': 8223,\n",
       " 'far': 3062,\n",
       " 'urgently': 9968,\n",
       " 'two': 9764,\n",
       " 'receipt': 7795,\n",
       " 'sent': 8447,\n",
       " 'closed': 1586,\n",
       " 'european': 2875,\n",
       " 'attendant': 609,\n",
       " 'paris': 7090,\n",
       " 'frankfurt': 3403,\n",
       " 'fabrice': 3015,\n",
       " 'very': 10077,\n",
       " 'frustrated': 3462,\n",
       " 'serviceopen': 8468,\n",
       " 'earlier': 2635,\n",
       " 'rip': 8121,\n",
       " 'terrible': 9330,\n",
       " 'military': 6283,\n",
       " 'member': 6206,\n",
       " 'unitedairlines': 9872,\n",
       " 'fault': 3080,\n",
       " 'ord': 6931,\n",
       " 'hungry': 4981,\n",
       " 'want': 10184,\n",
       " 'stop': 9010,\n",
       " 'much': 6454,\n",
       " 'amazing': 324,\n",
       " 'bussines': 1197,\n",
       " 'think': 9419,\n",
       " 'smoothly': 8728,\n",
       " 'comment': 1692,\n",
       " 'care': 1299,\n",
       " 'contacting': 1828,\n",
       " 'awake': 673,\n",
       " 'protected': 7595,\n",
       " 'flightr': 3251,\n",
       " 'making': 6048,\n",
       " 'effort': 2688,\n",
       " 'credit': 1966,\n",
       " 'instead': 5215,\n",
       " 'fwiw': 3513,\n",
       " 'loweredexpectations': 5959,\n",
       " 'doesn': 2492,\n",
       " 'terminal': 9326,\n",
       " 'lga': 5770,\n",
       " 'precheck': 7451,\n",
       " 'fly': 3284,\n",
       " 'seen': 8415,\n",
       " 'such': 9094,\n",
       " 'incompetency': 5118,\n",
       " 'agent': 184,\n",
       " 'business': 1191,\n",
       " 'dfw': 2318,\n",
       " 'training': 9619,\n",
       " 'saving': 8312,\n",
       " 'sanity': 8282,\n",
       " 'right': 8114,\n",
       " 'httptcoeltboljul': 4309,\n",
       " 'yyz': 10607,\n",
       " 'cleared': 1566,\n",
       " 'up': 9943,\n",
       " 'beautifully': 813,\n",
       " 'check': 1443,\n",
       " 'happy': 3836,\n",
       " 'wife': 10354,\n",
       " 'th': 9351,\n",
       " 'bday': 796,\n",
       " 'fully': 3492,\n",
       " 'compensated': 1723,\n",
       " 'both': 1031,\n",
       " 'current': 2018,\n",
       " 'food': 3344,\n",
       " 'menu': 6217,\n",
       " 'anywhere': 437,\n",
       " 'online': 6892,\n",
       " 'flightling': 3244,\n",
       " 'telling': 9314,\n",
       " 'flyunited': 3318,\n",
       " 'provide': 7601,\n",
       " 'direct': 2366,\n",
       " 'explain': 2977,\n",
       " 'contacted': 1827,\n",
       " 'yesterday': 10557,\n",
       " 'nothing': 6736,\n",
       " 'suggested': 9108,\n",
       " 'compensation': 1726,\n",
       " 'cust': 2025,\n",
       " 'bc': 793,\n",
       " 'ur': 9965,\n",
       " 'won': 10418,\n",
       " 'end': 2763,\n",
       " 'goin': 3636,\n",
       " 'httptcozjlztua': 4948,\n",
       " 'bravo': 1069,\n",
       " 'handling': 3817,\n",
       " 'msp': 6443,\n",
       " 'phx': 7257,\n",
       " 'missed': 6325,\n",
       " 'surprise': 9160,\n",
       " 'reason': 7776,\n",
       " 'tripnever': 9682,\n",
       " 'again': 177,\n",
       " 'look': 5907,\n",
       " 'gone': 3648,\n",
       " 'guess': 3769,\n",
       " 'someone': 8785,\n",
       " 'keep': 5543,\n",
       " 'failing': 3027,\n",
       " 'person': 7208,\n",
       " 'tell': 9313,\n",
       " 'inexcusable': 5163,\n",
       " 'behavior': 839,\n",
       " 'sorry': 8802,\n",
       " 'isn': 5312,\n",
       " 'enough': 2785,\n",
       " 'cltbna': 1600,\n",
       " 'maybemange': 6134,\n",
       " 'alittlebetter': 273,\n",
       " 'arrived': 529,\n",
       " 'lax': 5695,\n",
       " 'howisthatpossible': 4113,\n",
       " 'always': 311,\n",
       " 'same': 8267,\n",
       " 'thing': 9415,\n",
       " 'wu': 10511,\n",
       " 'different': 2348,\n",
       " 'story': 9017,\n",
       " 'fiancee': 3132,\n",
       " 'helped': 3929,\n",
       " 'shutting': 8592,\n",
       " 'data': 2102,\n",
       " 'land': 5652,\n",
       " 'come': 1674,\n",
       " 'indianapolis': 5142,\n",
       " 'int': 5227,\n",
       " 'intentionally': 5239,\n",
       " 'staff': 8917,\n",
       " 'unsuitable': 9929,\n",
       " 'lilly': 5810,\n",
       " 'sju': 8656,\n",
       " 'fabulous': 3016,\n",
       " 'sure': 9151,\n",
       " 'checked': 1444,\n",
       " 'into': 5261,\n",
       " 'bumped': 1169,\n",
       " 'tuesday': 9727,\n",
       " 'unacceptable': 9799,\n",
       " 'speak': 8844,\n",
       " 'waiting': 10156,\n",
       " 'hit': 3999,\n",
       " 'obviously': 6810,\n",
       " 'acceptable': 57,\n",
       " 'customerservicefail': 2035,\n",
       " 'male': 6052,\n",
       " 'must': 6472,\n",
       " 'being': 841,\n",
       " 'playing': 7332,\n",
       " 'game': 3526,\n",
       " 'bigger': 901,\n",
       " 'dick': 2335,\n",
       " 'people': 7188,\n",
       " 'chimid': 1482,\n",
       " 'son': 8791,\n",
       " 'avail': 650,\n",
       " 'rebook': 7786,\n",
       " 'twice': 9753,\n",
       " 'rep': 7951,\n",
       " 'said': 8256,\n",
       " 'way': 10216,\n",
       " 'phone': 7250,\n",
       " 'svc': 9173,\n",
       " 'mean': 6166,\n",
       " 'human': 4972,\n",
       " 'bad': 714,\n",
       " 'socialtantrum': 8764,\n",
       " 'followed': 3339,\n",
       " 'credited': 1968,\n",
       " 'request': 7985,\n",
       " 'merge': 6220,\n",
       " 'denied': 2236,\n",
       " 'fllsfo': 3270,\n",
       " 'unexpected': 9850,\n",
       " 'layover': 5707,\n",
       " 'vega': 10051,\n",
       " 'fuel': 3481,\n",
       " 'peep': 7177,\n",
       " 'bought': 1036,\n",
       " 'sneaky': 8745,\n",
       " 'companion': 1712,\n",
       " 'doing': 2499,\n",
       " 'message': 6226,\n",
       " 'done': 2511,\n",
       " 'den': 2230,\n",
       " 'information': 5176,\n",
       " 'super': 9132,\n",
       " 'bowl': 1045,\n",
       " 'headed': 3886,\n",
       " 'clt': 1599,\n",
       " 'funny': 3503,\n",
       " 'hear': 3893,\n",
       " 'ring': 8117,\n",
       " 'once': 6876,\n",
       " 'entire': 2803,\n",
       " 'groan': 3736,\n",
       " 'claimed': 1540,\n",
       " 'treated': 9664,\n",
       " 'sb': 8321,\n",
       " 'um': 9792,\n",
       " 'knew': 5601,\n",
       " 'storm': 9016,\n",
       " 'useless': 9995,\n",
       " 'air': 213,\n",
       " 'accordingly': 76,\n",
       " 'idiot': 5024,\n",
       " 'admit': 135,\n",
       " 'clue': 1603,\n",
       " 'denver': 2242,\n",
       " 'unfriendlyskies': 9859,\n",
       " 'searching': 8381,\n",
       " 'flts': 3278,\n",
       " 'site': 8636,\n",
       " 'offered': 6831,\n",
       " 'seg': 8418,\n",
       " 'falseadvertising': 3049,\n",
       " 'san': 8273,\n",
       " 'diego': 2342,\n",
       " 'empty': 2754,\n",
       " 'desk': 2287,\n",
       " 're': 7746,\n",
       " 'anything': 433,\n",
       " 'seguinej': 8421,\n",
       " 'accepting': 59,\n",
       " 'hang': 3821,\n",
       " 'fantastic': 3059,\n",
       " 'usair': 9974,\n",
       " 'rescheduled': 8001,\n",
       " 'notify': 6744,\n",
       " 'except': 2920,\n",
       " 'possibly': 7416,\n",
       " 'phonenot': 7252,\n",
       " 'helpful': 3930,\n",
       " 'co': 1627,\n",
       " 'three': 9447,\n",
       " 'disconnected': 2399,\n",
       " 'conf': 1774,\n",
       " 'ebhset': 2662,\n",
       " 'interview': 5259,\n",
       " 'although': 308,\n",
       " 'stranded': 9025,\n",
       " 'chicago': 1470,\n",
       " 'hare': 3854,\n",
       " 'another': 404,\n",
       " 'chance': 1401,\n",
       " 'crackerjack': 1942,\n",
       " 'meal': 6165,\n",
       " 'rising': 8127,\n",
       " 'sun': 9121,\n",
       " 'dca': 2125,\n",
       " 'morning': 6404,\n",
       " 'natca': 6511,\n",
       " 'avgeek': 660,\n",
       " 'httptcovahdekvoke': 4833,\n",
       " 'flysfo': 3311,\n",
       " 'httptcoxzbajmiekx': 4923,\n",
       " 'voucher': 10132,\n",
       " 'miscounting': 6311,\n",
       " 'course': 1916,\n",
       " 'hepl': 3946,\n",
       " 'only': 6894,\n",
       " 'flew': 3209,\n",
       " 'second': 8396,\n",
       " 'disgruntled': 2413,\n",
       " 'pas': 7106,\n",
       " 'admiral': 133,\n",
       " 'spending': 8860,\n",
       " 'typically': 9773,\n",
       " 'expires': 2974,\n",
       " 'info': 5173,\n",
       " 'country': 1910,\n",
       " 'swiss': 9200,\n",
       " 'international': 5250,\n",
       " 'contact': 1826,\n",
       " 'miami': 6246,\n",
       " 'updating': 9948,\n",
       " 'departure': 2255,\n",
       " 'paying': 7156,\n",
       " 'laguardia': 5644,\n",
       " 'lagos': 5643,\n",
       " 'nigeria': 6613,\n",
       " 'unprofessional': 9913,\n",
       " 'uncaring': 9816,\n",
       " 'ou': 6973,\n",
       " 'pick': 7265,\n",
       " 'bring': 1094,\n",
       " 'shuttle': 8593,\n",
       " 'double': 2530,\n",
       " 'concourse': 1765,\n",
       " 'yep': 10552,\n",
       " 'moved': 6425,\n",
       " 'showed': 8577,\n",
       " 'standby': 8929,\n",
       " 'abandoned': 20,\n",
       " 'boston': 1025,\n",
       " 'bound': 1041,\n",
       " 'flier': 3215,\n",
       " 'management': 6063,\n",
       " 'saveface': 8308,\n",
       " 'showup': 8584,\n",
       " 'near': 6531,\n",
       " 'sitting': 8643,\n",
       " 'yeah': 10542,\n",
       " 'wow': 10484,\n",
       " 'attdt': 604,\n",
       " 'decides': 2160,\n",
       " 'better': 880,\n",
       " 'fired': 3175,\n",
       " 'nice': 6606,\n",
       " 'thereisafirstforeverything': 9400,\n",
       " 'file': 3143,\n",
       " 'reference': 7854,\n",
       " 'located': 5874,\n",
       " 'piece': 7271,\n",
       " 'haven': 3869,\n",
       " 'delivered': 2215,\n",
       " 'lied': 5789,\n",
       " 'refund': 7872,\n",
       " 'notifying': 6745,\n",
       " 'alternative': 307,\n",
       " 'poor': 7387,\n",
       " 'httptcoepqqonhoh': 4315,\n",
       " 'promise': 7573,\n",
       " 'nvr': 6783,\n",
       " 'sum': 9118,\n",
       " 'else': 2718,\n",
       " 'amazed': 323,\n",
       " 'lack': 5637,\n",
       " 'communication': 1703,\n",
       " 'fastest': 3074,\n",
       " 'achieve': 86,\n",
       " 'computer': 1755,\n",
       " 'kudos': 5626,\n",
       " 'usually': 10003,\n",
       " 'panic': 7077,\n",
       " 'status': 8954,\n",
       " 'ffl': 3127,\n",
       " 'group': 3744,\n",
       " 'actually': 110,\n",
       " 'hate': 3863,\n",
       " 'isi': 5306,\n",
       " 'thats': 9376,\n",
       " 'heard': 3894,\n",
       " 'bump': 1168,\n",
       " 'closer': 1588,\n",
       " 'understanding': 9837,\n",
       " 'situation': 8646,\n",
       " 'opened': 6910,\n",
       " 'premium': 7476,\n",
       " 'wifi': 10356,\n",
       " 'decent': 2156,\n",
       " 'slowfi': 8705,\n",
       " 'mileageplus': 6275,\n",
       " 'signup': 8610,\n",
       " 'page': 7058,\n",
       " 'jb': 5393,\n",
       " 'platinum': 7325,\n",
       " 'tired': 9511,\n",
       " 'overchging': 7012,\n",
       " 'bg': 892,\n",
       " 'herded': 3951,\n",
       " 'cattleslaughter': 1344,\n",
       " 'aircanada': 218,\n",
       " 'connecting': 1798,\n",
       " 'good': 3653,\n",
       " 'businessfirst': 1192,\n",
       " 'took': 9571,\n",
       " 'leg': 5739,\n",
       " 'route': 8187,\n",
       " 'jet': 5414,\n",
       " 'blue': 968,\n",
       " 'treat': 9663,\n",
       " 'properly': 7588,\n",
       " 'fan': 3057,\n",
       " 'brand': 1059,\n",
       " 'rock': 8163,\n",
       " 'iahhnl': 5004,\n",
       " 'sfo': 8489,\n",
       " 'reactive': 7754,\n",
       " 'proactive': 7533,\n",
       " 'literally': 5840,\n",
       " 'rather': 7736,\n",
       " 'mom': 6370,\n",
       " 'dr': 2552,\n",
       " 'appointment': 475,\n",
       " 'cun': 2012,\n",
       " 'advisory': 153,\n",
       " 'charged': 1417,\n",
       " 'reschedule': 8000,\n",
       " 'flighted': 3227,\n",
       " 'refusing': 7879,\n",
       " 'deal': 2141,\n",
       " 'changed': 1403,\n",
       " 'usairway': 9977,\n",
       " 'getting': 3581,\n",
       " 'iah': 5002,\n",
       " 'patient': 7136,\n",
       " 'luxurious': 5999,\n",
       " 'queue': 7670,\n",
       " 'eta': 2863,\n",
       " 'name': 6491,\n",
       " 'department': 2253,\n",
       " 'under': 9830,\n",
       " 'accountability': 78,\n",
       " 'website': 10248,\n",
       " 'seriously': 8461,\n",
       " 'center': 1374,\n",
       " 'tempting': 9319,\n",
       " 'sodone': 8768,\n",
       " 'realize': 7767,\n",
       " 'banning': 759,\n",
       " 'peanut': 7170,\n",
       " 'allergic': 279,\n",
       " 'ignores': 5041,\n",
       " 'pnut': 7367,\n",
       " 'oil': 6848,\n",
       " 'dust': 2621,\n",
       " 'previous': 7507,\n",
       " 'award': 674,\n",
       " 'policy': 7381,\n",
       " 'card': 1297,\n",
       " 'holder': 4013,\n",
       " 'seeing': 8408,\n",
       " 'chart': 1426,\n",
       " 'cause': 1347,\n",
       " 'suck': 9095,\n",
       " 'weasel': 10238,\n",
       " 'room': 8181,\n",
       " 'claiming': 1541,\n",
       " 'httptcoflcnnnusd': 4338,\n",
       " 'nonrefundable': 6687,\n",
       " 'hence': 3943,\n",
       " 'wrote': 10500,\n",
       " 'sense': 8444,\n",
       " 'nothanks': 6733,\n",
       " 'possible': 7415,\n",
       " 'flightlation': 3237,\n",
       " 'rectify': 7826,\n",
       " 'excited': 2927,\n",
       " 'saw': 8315,\n",
       " 'ionlyflyblue': 5285,\n",
       " 'learning': 5726,\n",
       " 'famous': 3055,\n",
       " 'social': 8763,\n",
       " 'medium': 6188,\n",
       " 'marketing': 6097,\n",
       " 'twitter': 9758,\n",
       " 'asset': 563,\n",
       " 'phdmama': 7225,\n",
       " 'believe': 847,\n",
       " 'receive': 7796,\n",
       " 'upcoming': 9945,\n",
       " 'true': 9696,\n",
       " 'jeffsmisek': 5407,\n",
       " 'robertfor': 8154,\n",
       " 'fiorettindward': 3172,\n",
       " 'garciachicago': 3532,\n",
       " 'faa': 3011,\n",
       " 'invest': 5269,\n",
       " 'miss': 6324,\n",
       " 'wk': 10398,\n",
       " 'httptcojvjzzaa': 4473,\n",
       " 'happening': 3831,\n",
       " 'wasn': 10201,\n",
       " 'working': 10443,\n",
       " 'wichita': 10352,\n",
       " 'fall': 3044,\n",
       " 'unknowledgeable': 9889,\n",
       " 'rt': 8198,\n",
       " 'httptcopkiqhi': 4655,\n",
       " 'yay': 10538,\n",
       " 'glitchy': 3618,\n",
       " 'tracking': 9613,\n",
       " 'destination': 2297,\n",
       " 'app': 453,\n",
       " 'tried': 9676,\n",
       " 'browser': 1123,\n",
       " 'continues': 1846,\n",
       " 'outbound': 6983,\n",
       " 'inbound': 5095,\n",
       " 'ewr': 2905,\n",
       " 'ready': 7760,\n",
       " 'dal': 2068,\n",
       " 'early': 2636,\n",
       " 'sofly': 8769,\n",
       " 'firststari': 3184,\n",
       " ...}"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the vocabulary of CountVectorizer (in this case only for dataset where target variable is \"one hot\" encoded)\n",
    "C_vectorizer_d.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Use TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for target dummy_variable\n",
    "\n",
    "#creating vectorizer - T in name means TfIdf, d at the end means dummy target variable\n",
    "T_vectorizer_d=TfidfVectorizer()\n",
    "\n",
    "#vectorizer is fitted with trainning data\n",
    "T_vectorizer_d.fit(x_train_d)\n",
    "\n",
    "#transform is applied on both, trainning and test data\n",
    "x_train_features_tfIdfV_d=T_vectorizer_d.transform(x_train_d)\n",
    "x_test_features_tfIdfV_d=T_vectorizer_d.transform(x_test_d)\n",
    "\n",
    "x_train_features_tfIdfV_d=x_train_features_tfIdfV_d.toarray()\n",
    "x_test_features_tfIdfV_d=x_test_features_tfIdfV_d.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for target label encoded\n",
    "\n",
    "#creating vectorizer - T in name means TfIdf, l at the end means label encoded target variable\n",
    "T_vectorizer_l=TfidfVectorizer()\n",
    "\n",
    "#vectorizer is fitted with trainning data\n",
    "T_vectorizer_l.fit(x_train_l)\n",
    "\n",
    "#transform is applied on both, trainning and test data\n",
    "x_train_features_tfIdfV_l=T_vectorizer_l.transform(x_train_l)\n",
    "x_test_features_tfIdfV_l=T_vectorizer_l.transform(x_test_l)\n",
    "\n",
    "x_train_features_tfIdfV_l=x_train_features_tfIdfV_l.toarray()\n",
    "x_test_features_tfIdfV_l=x_test_features_tfIdfV_l.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'united': 9869,\n",
       " 'flt': 3277,\n",
       " 'cancelled': 1266,\n",
       " 'flightled': 3240,\n",
       " 'and': 368,\n",
       " 'get': 3569,\n",
       " 'email': 2721,\n",
       " 'am': 317,\n",
       " 'what': 10301,\n",
       " 'happened': 3829,\n",
       " 'to': 9537,\n",
       " 'courtesy': 1920,\n",
       " 'phn': 7246,\n",
       " 'call': 1246,\n",
       " 'had': 3789,\n",
       " 'book': 1001,\n",
       " 'diff': 2346,\n",
       " 'airline': 223,\n",
       " 'amp': 356,\n",
       " 'city': 1533,\n",
       " 'delayed': 2194,\n",
       " 'because': 818,\n",
       " 'of': 6824,\n",
       " 'maintenance': 6037,\n",
       " 'that': 9374,\n",
       " 'fixed': 3191,\n",
       " 'but': 1200,\n",
       " 'can': 1262,\n",
       " 'board': 979,\n",
       " 'flight': 3217,\n",
       " 'crew': 1969,\n",
       " 'didn': 2338,\n",
       " 'stay': 8958,\n",
       " 'in': 5088,\n",
       " 'boarding': 981,\n",
       " 'area': 506,\n",
       " 'fail': 3024,\n",
       " 'my': 6479,\n",
       " 'dad': 2059,\n",
       " 'booked': 1002,\n",
       " 'through': 9453,\n",
       " 'orbitz': 6930,\n",
       " 'due': 2602,\n",
       " 'weather': 10239,\n",
       " 'he': 3883,\n",
       " 'make': 6042,\n",
       " 'it': 5323,\n",
       " 'the': 9377,\n",
       " 'airport': 233,\n",
       " 'you': 10565,\n",
       " 'help': 3926,\n",
       " 'him': 3984,\n",
       " 'read': 7755,\n",
       " 'bio': 913,\n",
       " 'see': 8407,\n",
       " 'who': 10337,\n",
       " 'work': 10436,\n",
       " 'with': 10391,\n",
       " 'have': 3868,\n",
       " 'never': 6568,\n",
       " 'encountered': 2760,\n",
       " 'this': 9427,\n",
       " 'your': 10573,\n",
       " 'before': 829,\n",
       " 'disappointed': 2386,\n",
       " 'is': 5303,\n",
       " 'an': 363,\n",
       " 'understatement': 9839,\n",
       " 'jetblue': 5416,\n",
       " 'our': 6977,\n",
       " 'fleet': 3208,\n",
       " 'on': 6871,\n",
       " 'fleek': 3207,\n",
       " 'httptcomwsgolgo': 4571,\n",
       " 'thanks': 9363,\n",
       " 'love': 5941,\n",
       " 'report': 7971,\n",
       " 'how': 4110,\n",
       " 'horrible': 4070,\n",
       " 'team': 9296,\n",
       " 'let': 5758,\n",
       " 'worse': 10454,\n",
       " 'they': 9409,\n",
       " 'seat': 8384,\n",
       " 'out': 6981,\n",
       " 'all': 275,\n",
       " 'snack': 8736,\n",
       " 'do': 2485,\n",
       " 'any': 425,\n",
       " 'lie': 5788,\n",
       " 'flat': 3201,\n",
       " 'seating': 8390,\n",
       " 'from': 3449,\n",
       " 'stl': 8996,\n",
       " 'pdx': 7165,\n",
       " 'around': 522,\n",
       " 'date': 2103,\n",
       " 'march': 6082,\n",
       " 'wa': 10147,\n",
       " 'not': 6723,\n",
       " 'allowed': 288,\n",
       " 'drop': 2580,\n",
       " 'bag': 730,\n",
       " 'off': 6825,\n",
       " 'for': 3351,\n",
       " 'running': 8222,\n",
       " 'min': 6286,\n",
       " 'late': 5674,\n",
       " 'turn': 9736,\n",
       " 'left': 5738,\n",
       " 'over': 7004,\n",
       " 'hour': 4096,\n",
       " 'americanair': 334,\n",
       " 'trying': 9712,\n",
       " 'change': 1402,\n",
       " 'time': 9490,\n",
       " 'already': 299,\n",
       " 'purchased': 7638,\n",
       " 'told': 9551,\n",
       " 'pay': 7153,\n",
       " 'fee': 3103,\n",
       " 'ridiculous': 8110,\n",
       " 'virginamerica': 10103,\n",
       " 'guy': 3781,\n",
       " 'know': 5603,\n",
       " 'checkin': 1445,\n",
       " 'link': 5822,\n",
       " 'are': 505,\n",
       " 'broken': 1112,\n",
       " 'httptconpxbobmr': 4597,\n",
       " 'we': 10233,\n",
       " 'll': 5856,\n",
       " 'luggage': 5983,\n",
       " 'after': 172,\n",
       " 'flying': 3295,\n",
       " 'saturday': 8301,\n",
       " 'where': 10318,\n",
       " 'expecting': 2959,\n",
       " 'ice': 5008,\n",
       " 'snow': 8747,\n",
       " 'when': 10316,\n",
       " 'should': 8564,\n",
       " 'start': 8938,\n",
       " 'looking': 5911,\n",
       " 'travel': 9642,\n",
       " 'waiver': 10165,\n",
       " 'southwestair': 8823,\n",
       " 'number': 6776,\n",
       " 'use': 9990,\n",
       " 'outside': 6997,\n",
       " 'thx': 9465,\n",
       " 'yes': 10553,\n",
       " 'waited': 10154,\n",
       " 'line': 5817,\n",
       " 'almost': 295,\n",
       " 'so': 8758,\n",
       " 'some': 8782,\n",
       " 'passenger': 7114,\n",
       " 'just': 5504,\n",
       " 'wanting': 10187,\n",
       " 'wait': 10152,\n",
       " 'past': 7124,\n",
       " 'ask': 553,\n",
       " 'slc': 8682,\n",
       " 'checkinbag': 1446,\n",
       " 'if': 5033,\n",
       " 'found': 3388,\n",
       " 'dark': 2099,\n",
       " 'blueblackish': 969,\n",
       " 'fit': 3187,\n",
       " 'bit': 921,\n",
       " 'flex': 3210,\n",
       " 'would': 10473,\n",
       " 've': 10048,\n",
       " 'lost': 5925,\n",
       " 'there': 9398,\n",
       " 'pm': 7363,\n",
       " 'mt': 6447,\n",
       " 'stuffy': 9069,\n",
       " 'plane': 7309,\n",
       " 'until': 9933,\n",
       " 'could': 1900,\n",
       " 'then': 9393,\n",
       " 'more': 6401,\n",
       " 'hr': 4117,\n",
       " 'their': 9386,\n",
       " 'americanairlines': 337,\n",
       " 'respond': 8030,\n",
       " 'tweet': 9747,\n",
       " 'dm': 2473,\n",
       " 'really': 7770,\n",
       " 'sad': 8241,\n",
       " 'feeling': 3107,\n",
       " 'be': 801,\n",
       " 'ignored': 5040,\n",
       " 'worst': 10455,\n",
       " 'don': 2507,\n",
       " 'me': 6164,\n",
       " 'hold': 4012,\n",
       " 'enter': 2795,\n",
       " 'callback': 1247,\n",
       " 'middle': 6254,\n",
       " 'night': 6615,\n",
       " 'will': 10363,\n",
       " 'third': 9424,\n",
       " 'been': 826,\n",
       " 'called': 1249,\n",
       " 'by': 1218,\n",
       " 'hung': 4979,\n",
       " 'anyone': 429,\n",
       " 'speaks': 8846,\n",
       " 'now': 6759,\n",
       " 'captain': 1290,\n",
       " 'apologize': 446,\n",
       " 'delay': 2193,\n",
       " 'company': 1714,\n",
       " 'open': 6909,\n",
       " 'gate': 3537,\n",
       " 'glance': 3612,\n",
       " 'starboard': 8934,\n",
       " 'side': 8599,\n",
       " 'ua': 9780,\n",
       " 'take': 9246,\n",
       " 'without': 10394,\n",
       " 'missing': 6330,\n",
       " 'galley': 3525,\n",
       " 'cart': 1324,\n",
       " 'no': 6636,\n",
       " 'one': 6878,\n",
       " 'find': 3161,\n",
       " 'pax': 7151,\n",
       " 'seated': 8389,\n",
       " 'last': 5667,\n",
       " 'bereavement': 865,\n",
       " 'discount': 2403,\n",
       " 'airfare': 222,\n",
       " 'grandfather': 3697,\n",
       " 'passed': 7112,\n",
       " 'need': 6536,\n",
       " 'attend': 608,\n",
       " 'his': 3995,\n",
       " 'funeral': 3501,\n",
       " 'week': 10253,\n",
       " 'usairways': 9978,\n",
       " 'issue': 5316,\n",
       " 'still': 8987,\n",
       " 'resolved': 8023,\n",
       " 'hope': 4058,\n",
       " 'every': 2890,\n",
       " 'minute': 6302,\n",
       " 'talk': 9257,\n",
       " 'system': 9229,\n",
       " 'fucking': 3477,\n",
       " 'joke': 5465,\n",
       " 'kidding': 5569,\n",
       " 'answering': 410,\n",
       " 'reserv': 8014,\n",
       " 'high': 3969,\n",
       " 'volume': 10127,\n",
       " 'even': 2880,\n",
       " 'option': 6926,\n",
       " 'brutal': 1130,\n",
       " 'reservation': 8015,\n",
       " 'follow': 3336,\n",
       " 'detail': 2304,\n",
       " 'mht': 6241,\n",
       " 'fun': 3494,\n",
       " 'kid': 5568,\n",
       " 'grandkids': 3698,\n",
       " 'them': 9388,\n",
       " 'jack': 5357,\n",
       " 'say': 8317,\n",
       " 'hi': 3963,\n",
       " 'httptcobhooiytzq': 4209,\n",
       " 'great': 3711,\n",
       " 'doe': 2491,\n",
       " 'im': 5056,\n",
       " 'reward': 8094,\n",
       " 'ticket': 9470,\n",
       " 'world': 10446,\n",
       " 'partner': 7103,\n",
       " 'automated': 644,\n",
       " 'wont': 10426,\n",
       " 'job': 5458,\n",
       " 'aa': 0,\n",
       " 'employee': 2751,\n",
       " 'were': 10279,\n",
       " 'rude': 8206,\n",
       " 'unwilling': 9941,\n",
       " 'mile': 6273,\n",
       " 'rotten': 8183,\n",
       " 'cherry': 1462,\n",
       " 'top': 9576,\n",
       " 'dog': 2495,\n",
       " 'shit': 8543,\n",
       " 'sunday': 9123,\n",
       " 'nocareforcustomers': 6645,\n",
       " 'got': 3674,\n",
       " 'known': 5607,\n",
       " 'traveler': 9644,\n",
       " 'like': 5804,\n",
       " 'add': 119,\n",
       " 'best': 868,\n",
       " 'heading': 3888,\n",
       " 'milan': 6271,\n",
       " 'wednesday': 10251,\n",
       " 'big': 900,\n",
       " 'family': 3052,\n",
       " 'at': 587,\n",
       " 'point': 7371,\n",
       " 'made': 6017,\n",
       " 'home': 4026,\n",
       " 'own': 7037,\n",
       " 'httptcoltxjkbo': 4536,\n",
       " 'dead': 2137,\n",
       " 'yet': 10559,\n",
       " 'dealing': 2142,\n",
       " 'since': 8621,\n",
       " 'wouldve': 10479,\n",
       " 'least': 5729,\n",
       " 'liked': 5806,\n",
       " 'ella': 2711,\n",
       " 'perform': 7197,\n",
       " 'lol': 5894,\n",
       " 'reach': 7748,\n",
       " 'american': 333,\n",
       " 'evening': 2881,\n",
       " 'customer': 2029,\n",
       " 'service': 8465,\n",
       " 'ever': 2888,\n",
       " 'also': 303,\n",
       " 'southwest': 8822,\n",
       " 'other': 6966,\n",
       " 'special': 8848,\n",
       " 'view': 10090,\n",
       " 'downtown': 2547,\n",
       " 'los': 5919,\n",
       " 'angeles': 380,\n",
       " 'hollywood': 4023,\n",
       " 'sign': 8603,\n",
       " 'beyond': 887,\n",
       " 'rain': 7704,\n",
       " 'mountain': 6420,\n",
       " 'httptcodwnfibtr': 4290,\n",
       " 'please': 7339,\n",
       " 'she': 8527,\n",
       " 'went': 10277,\n",
       " 'above': 40,\n",
       " 'her': 3947,\n",
       " 'priority': 7526,\n",
       " 'hiltonworldwide': 3983,\n",
       " 'caravannyc': 1296,\n",
       " 'maysvillenyc': 6136,\n",
       " 'go': 3628,\n",
       " 'join': 5463,\n",
       " 'first': 3181,\n",
       " 'trip': 9678,\n",
       " 'back': 702,\n",
       " 'nyc': 6787,\n",
       " 'tourist': 9598,\n",
       " 'httptcoegaejtrglb': 4303,\n",
       " 'ny': 6786,\n",
       " 'scheduled': 8344,\n",
       " 'leave': 5733,\n",
       " 'than': 9355,\n",
       " 'checking': 1447,\n",
       " 'huge': 4968,\n",
       " 'give': 3602,\n",
       " 'answer': 408,\n",
       " 'why': 10345,\n",
       " 'long': 5900,\n",
       " 'compensate': 1722,\n",
       " 'lima': 5811,\n",
       " 'cuzco': 2048,\n",
       " 'hello': 3924,\n",
       " 'swa': 9176,\n",
       " 'poc': 7369,\n",
       " 'partnership': 7104,\n",
       " 'nonprofit': 6686,\n",
       " 'organization': 6948,\n",
       " 'bwi': 1212,\n",
       " 'address': 125,\n",
       " 'put': 7649,\n",
       " 'next': 6596,\n",
       " 'available': 652,\n",
       " 'ohare': 6843,\n",
       " 'today': 9540,\n",
       " 'unpleasant': 9908,\n",
       " 'experience': 2968,\n",
       " 'life': 5791,\n",
       " 'might': 6265,\n",
       " 'till': 9487,\n",
       " 'tomorrow': 9560,\n",
       " 'insane': 5200,\n",
       " 'wish': 10390,\n",
       " 'notified': 6743,\n",
       " 'flyus': 3319,\n",
       " 'ripoff': 8122,\n",
       " 'rebooked': 7787,\n",
       " 'whole': 10340,\n",
       " 'day': 2109,\n",
       " 'vacation': 10024,\n",
       " 'these': 9402,\n",
       " 'fare': 3064,\n",
       " 'notch': 6726,\n",
       " 'wonder': 10419,\n",
       " 'cabin': 1228,\n",
       " 'filthy': 3153,\n",
       " 'badservice': 726,\n",
       " 'extend': 2989,\n",
       " 'rtn': 8200,\n",
       " 'nd': 6528,\n",
       " 'dropped': 2582,\n",
       " 'noworse': 6765,\n",
       " 'badcustomerservice': 719,\n",
       " 'according': 75,\n",
       " 'jfk': 5435,\n",
       " 'plenty': 7351,\n",
       " 'landing': 5655,\n",
       " 'problem': 7539,\n",
       " 'thank': 9356,\n",
       " 'cincyjust': 1520,\n",
       " 'landedyou': 5654,\n",
       " 'frequent': 3426,\n",
       " 'flyer': 3290,\n",
       " 'account': 77,\n",
       " 'incredibly': 5133,\n",
       " 'frustrating': 3463,\n",
       " 'anytime': 434,\n",
       " 'sugafly': 9105,\n",
       " 'airway': 244,\n",
       " 'qantas': 7655,\n",
       " 'notification': 6742,\n",
       " 'coming': 1687,\n",
       " 'sw': 9175,\n",
       " 'rsw': 8197,\n",
       " 'mke': 6345,\n",
       " 'update': 9946,\n",
       " 'baggage': 732,\n",
       " 'claim': 1539,\n",
       " 'incompetence': 5117,\n",
       " 'overwhelming': 7031,\n",
       " 'reply': 7968,\n",
       " 'share': 8520,\n",
       " 'thought': 9439,\n",
       " 'greater': 3713,\n",
       " 'via': 10081,\n",
       " 'web': 10245,\n",
       " 'form': 3371,\n",
       " 'taking': 9253,\n",
       " 'providing': 7606,\n",
       " 'about': 39,\n",
       " 'which': 10327,\n",
       " 'httptcoambsig': 4169,\n",
       " 'guideline': 3776,\n",
       " 'xx': 10528,\n",
       " 'taller': 9260,\n",
       " 'gonna': 3651,\n",
       " 'going': 3637,\n",
       " 'weekend': 10255,\n",
       " 'friend': 3437,\n",
       " 'birthday': 919,\n",
       " 'reflight': 7861,\n",
       " 'booking': 1003,\n",
       " 'arrive': 528,\n",
       " 'ha': 3785,\n",
       " 'plan': 7307,\n",
       " 'dollar': 2502,\n",
       " 'laxlas': 5699,\n",
       " 'here': 3952,\n",
       " 'few': 3124,\n",
       " 'month': 6390,\n",
       " 'ago': 193,\n",
       " 'none': 6679,\n",
       " 'weird': 10263,\n",
       " 'club': 1602,\n",
       " 'busiest': 1190,\n",
       " 'apology': 450,\n",
       " 'fix': 3190,\n",
       " 'competent': 1728,\n",
       " 'manner': 6075,\n",
       " 'rhonda': 8096,\n",
       " 'atlanta': 593,\n",
       " 'redeemed': 7833,\n",
       " 'straightened': 9023,\n",
       " 'did': 2337,\n",
       " 'expect': 2956,\n",
       " 'response': 8034,\n",
       " 'fiscal': 3185,\n",
       " 'year': 10543,\n",
       " 'calendar': 1242,\n",
       " 'new': 6577,\n",
       " 'schedule': 8342,\n",
       " 'nonstop': 6690,\n",
       " 'phl': 7237,\n",
       " 'fll': 3267,\n",
       " 'or': 6927,\n",
       " 'pbi': 7161,\n",
       " 'free': 3416,\n",
       " 'move': 6423,\n",
       " 'between': 884,\n",
       " 'those': 9437,\n",
       " 'shouldn': 8571,\n",
       " 'longer': 5904,\n",
       " 'itself': 5341,\n",
       " 'runway': 8223,\n",
       " 'far': 3062,\n",
       " 'urgently': 9968,\n",
       " 'two': 9764,\n",
       " 'receipt': 7795,\n",
       " 'sent': 8447,\n",
       " 'closed': 1586,\n",
       " 'european': 2875,\n",
       " 'attendant': 609,\n",
       " 'paris': 7090,\n",
       " 'frankfurt': 3403,\n",
       " 'fabrice': 3015,\n",
       " 'very': 10077,\n",
       " 'frustrated': 3462,\n",
       " 'serviceopen': 8468,\n",
       " 'earlier': 2635,\n",
       " 'rip': 8121,\n",
       " 'terrible': 9330,\n",
       " 'military': 6283,\n",
       " 'member': 6206,\n",
       " 'unitedairlines': 9872,\n",
       " 'fault': 3080,\n",
       " 'ord': 6931,\n",
       " 'hungry': 4981,\n",
       " 'want': 10184,\n",
       " 'stop': 9010,\n",
       " 'much': 6454,\n",
       " 'amazing': 324,\n",
       " 'bussines': 1197,\n",
       " 'think': 9419,\n",
       " 'smoothly': 8728,\n",
       " 'comment': 1692,\n",
       " 'care': 1299,\n",
       " 'contacting': 1828,\n",
       " 'awake': 673,\n",
       " 'protected': 7595,\n",
       " 'flightr': 3251,\n",
       " 'making': 6048,\n",
       " 'effort': 2688,\n",
       " 'credit': 1966,\n",
       " 'instead': 5215,\n",
       " 'fwiw': 3513,\n",
       " 'loweredexpectations': 5959,\n",
       " 'doesn': 2492,\n",
       " 'terminal': 9326,\n",
       " 'lga': 5770,\n",
       " 'precheck': 7451,\n",
       " 'fly': 3284,\n",
       " 'seen': 8415,\n",
       " 'such': 9094,\n",
       " 'incompetency': 5118,\n",
       " 'agent': 184,\n",
       " 'business': 1191,\n",
       " 'dfw': 2318,\n",
       " 'training': 9619,\n",
       " 'saving': 8312,\n",
       " 'sanity': 8282,\n",
       " 'right': 8114,\n",
       " 'httptcoeltboljul': 4309,\n",
       " 'yyz': 10607,\n",
       " 'cleared': 1566,\n",
       " 'up': 9943,\n",
       " 'beautifully': 813,\n",
       " 'check': 1443,\n",
       " 'happy': 3836,\n",
       " 'wife': 10354,\n",
       " 'th': 9351,\n",
       " 'bday': 796,\n",
       " 'fully': 3492,\n",
       " 'compensated': 1723,\n",
       " 'both': 1031,\n",
       " 'current': 2018,\n",
       " 'food': 3344,\n",
       " 'menu': 6217,\n",
       " 'anywhere': 437,\n",
       " 'online': 6892,\n",
       " 'flightling': 3244,\n",
       " 'telling': 9314,\n",
       " 'flyunited': 3318,\n",
       " 'provide': 7601,\n",
       " 'direct': 2366,\n",
       " 'explain': 2977,\n",
       " 'contacted': 1827,\n",
       " 'yesterday': 10557,\n",
       " 'nothing': 6736,\n",
       " 'suggested': 9108,\n",
       " 'compensation': 1726,\n",
       " 'cust': 2025,\n",
       " 'bc': 793,\n",
       " 'ur': 9965,\n",
       " 'won': 10418,\n",
       " 'end': 2763,\n",
       " 'goin': 3636,\n",
       " 'httptcozjlztua': 4948,\n",
       " 'bravo': 1069,\n",
       " 'handling': 3817,\n",
       " 'msp': 6443,\n",
       " 'phx': 7257,\n",
       " 'missed': 6325,\n",
       " 'surprise': 9160,\n",
       " 'reason': 7776,\n",
       " 'tripnever': 9682,\n",
       " 'again': 177,\n",
       " 'look': 5907,\n",
       " 'gone': 3648,\n",
       " 'guess': 3769,\n",
       " 'someone': 8785,\n",
       " 'keep': 5543,\n",
       " 'failing': 3027,\n",
       " 'person': 7208,\n",
       " 'tell': 9313,\n",
       " 'inexcusable': 5163,\n",
       " 'behavior': 839,\n",
       " 'sorry': 8802,\n",
       " 'isn': 5312,\n",
       " 'enough': 2785,\n",
       " 'cltbna': 1600,\n",
       " 'maybemange': 6134,\n",
       " 'alittlebetter': 273,\n",
       " 'arrived': 529,\n",
       " 'lax': 5695,\n",
       " 'howisthatpossible': 4113,\n",
       " 'always': 311,\n",
       " 'same': 8267,\n",
       " 'thing': 9415,\n",
       " 'wu': 10511,\n",
       " 'different': 2348,\n",
       " 'story': 9017,\n",
       " 'fiancee': 3132,\n",
       " 'helped': 3929,\n",
       " 'shutting': 8592,\n",
       " 'data': 2102,\n",
       " 'land': 5652,\n",
       " 'come': 1674,\n",
       " 'indianapolis': 5142,\n",
       " 'int': 5227,\n",
       " 'intentionally': 5239,\n",
       " 'staff': 8917,\n",
       " 'unsuitable': 9929,\n",
       " 'lilly': 5810,\n",
       " 'sju': 8656,\n",
       " 'fabulous': 3016,\n",
       " 'sure': 9151,\n",
       " 'checked': 1444,\n",
       " 'into': 5261,\n",
       " 'bumped': 1169,\n",
       " 'tuesday': 9727,\n",
       " 'unacceptable': 9799,\n",
       " 'speak': 8844,\n",
       " 'waiting': 10156,\n",
       " 'hit': 3999,\n",
       " 'obviously': 6810,\n",
       " 'acceptable': 57,\n",
       " 'customerservicefail': 2035,\n",
       " 'male': 6052,\n",
       " 'must': 6472,\n",
       " 'being': 841,\n",
       " 'playing': 7332,\n",
       " 'game': 3526,\n",
       " 'bigger': 901,\n",
       " 'dick': 2335,\n",
       " 'people': 7188,\n",
       " 'chimid': 1482,\n",
       " 'son': 8791,\n",
       " 'avail': 650,\n",
       " 'rebook': 7786,\n",
       " 'twice': 9753,\n",
       " 'rep': 7951,\n",
       " 'said': 8256,\n",
       " 'way': 10216,\n",
       " 'phone': 7250,\n",
       " 'svc': 9173,\n",
       " 'mean': 6166,\n",
       " 'human': 4972,\n",
       " 'bad': 714,\n",
       " 'socialtantrum': 8764,\n",
       " 'followed': 3339,\n",
       " 'credited': 1968,\n",
       " 'request': 7985,\n",
       " 'merge': 6220,\n",
       " 'denied': 2236,\n",
       " 'fllsfo': 3270,\n",
       " 'unexpected': 9850,\n",
       " 'layover': 5707,\n",
       " 'vega': 10051,\n",
       " 'fuel': 3481,\n",
       " 'peep': 7177,\n",
       " 'bought': 1036,\n",
       " 'sneaky': 8745,\n",
       " 'companion': 1712,\n",
       " 'doing': 2499,\n",
       " 'message': 6226,\n",
       " 'done': 2511,\n",
       " 'den': 2230,\n",
       " 'information': 5176,\n",
       " 'super': 9132,\n",
       " 'bowl': 1045,\n",
       " 'headed': 3886,\n",
       " 'clt': 1599,\n",
       " 'funny': 3503,\n",
       " 'hear': 3893,\n",
       " 'ring': 8117,\n",
       " 'once': 6876,\n",
       " 'entire': 2803,\n",
       " 'groan': 3736,\n",
       " 'claimed': 1540,\n",
       " 'treated': 9664,\n",
       " 'sb': 8321,\n",
       " 'um': 9792,\n",
       " 'knew': 5601,\n",
       " 'storm': 9016,\n",
       " 'useless': 9995,\n",
       " 'air': 213,\n",
       " 'accordingly': 76,\n",
       " 'idiot': 5024,\n",
       " 'admit': 135,\n",
       " 'clue': 1603,\n",
       " 'denver': 2242,\n",
       " 'unfriendlyskies': 9859,\n",
       " 'searching': 8381,\n",
       " 'flts': 3278,\n",
       " 'site': 8636,\n",
       " 'offered': 6831,\n",
       " 'seg': 8418,\n",
       " 'falseadvertising': 3049,\n",
       " 'san': 8273,\n",
       " 'diego': 2342,\n",
       " 'empty': 2754,\n",
       " 'desk': 2287,\n",
       " 're': 7746,\n",
       " 'anything': 433,\n",
       " 'seguinej': 8421,\n",
       " 'accepting': 59,\n",
       " 'hang': 3821,\n",
       " 'fantastic': 3059,\n",
       " 'usair': 9974,\n",
       " 'rescheduled': 8001,\n",
       " 'notify': 6744,\n",
       " 'except': 2920,\n",
       " 'possibly': 7416,\n",
       " 'phonenot': 7252,\n",
       " 'helpful': 3930,\n",
       " 'co': 1627,\n",
       " 'three': 9447,\n",
       " 'disconnected': 2399,\n",
       " 'conf': 1774,\n",
       " 'ebhset': 2662,\n",
       " 'interview': 5259,\n",
       " 'although': 308,\n",
       " 'stranded': 9025,\n",
       " 'chicago': 1470,\n",
       " 'hare': 3854,\n",
       " 'another': 404,\n",
       " 'chance': 1401,\n",
       " 'crackerjack': 1942,\n",
       " 'meal': 6165,\n",
       " 'rising': 8127,\n",
       " 'sun': 9121,\n",
       " 'dca': 2125,\n",
       " 'morning': 6404,\n",
       " 'natca': 6511,\n",
       " 'avgeek': 660,\n",
       " 'httptcovahdekvoke': 4833,\n",
       " 'flysfo': 3311,\n",
       " 'httptcoxzbajmiekx': 4923,\n",
       " 'voucher': 10132,\n",
       " 'miscounting': 6311,\n",
       " 'course': 1916,\n",
       " 'hepl': 3946,\n",
       " 'only': 6894,\n",
       " 'flew': 3209,\n",
       " 'second': 8396,\n",
       " 'disgruntled': 2413,\n",
       " 'pas': 7106,\n",
       " 'admiral': 133,\n",
       " 'spending': 8860,\n",
       " 'typically': 9773,\n",
       " 'expires': 2974,\n",
       " 'info': 5173,\n",
       " 'country': 1910,\n",
       " 'swiss': 9200,\n",
       " 'international': 5250,\n",
       " 'contact': 1826,\n",
       " 'miami': 6246,\n",
       " 'updating': 9948,\n",
       " 'departure': 2255,\n",
       " 'paying': 7156,\n",
       " 'laguardia': 5644,\n",
       " 'lagos': 5643,\n",
       " 'nigeria': 6613,\n",
       " 'unprofessional': 9913,\n",
       " 'uncaring': 9816,\n",
       " 'ou': 6973,\n",
       " 'pick': 7265,\n",
       " 'bring': 1094,\n",
       " 'shuttle': 8593,\n",
       " 'double': 2530,\n",
       " 'concourse': 1765,\n",
       " 'yep': 10552,\n",
       " 'moved': 6425,\n",
       " 'showed': 8577,\n",
       " 'standby': 8929,\n",
       " 'abandoned': 20,\n",
       " 'boston': 1025,\n",
       " 'bound': 1041,\n",
       " 'flier': 3215,\n",
       " 'management': 6063,\n",
       " 'saveface': 8308,\n",
       " 'showup': 8584,\n",
       " 'near': 6531,\n",
       " 'sitting': 8643,\n",
       " 'yeah': 10542,\n",
       " 'wow': 10484,\n",
       " 'attdt': 604,\n",
       " 'decides': 2160,\n",
       " 'better': 880,\n",
       " 'fired': 3175,\n",
       " 'nice': 6606,\n",
       " 'thereisafirstforeverything': 9400,\n",
       " 'file': 3143,\n",
       " 'reference': 7854,\n",
       " 'located': 5874,\n",
       " 'piece': 7271,\n",
       " 'haven': 3869,\n",
       " 'delivered': 2215,\n",
       " 'lied': 5789,\n",
       " 'refund': 7872,\n",
       " 'notifying': 6745,\n",
       " 'alternative': 307,\n",
       " 'poor': 7387,\n",
       " 'httptcoepqqonhoh': 4315,\n",
       " 'promise': 7573,\n",
       " 'nvr': 6783,\n",
       " 'sum': 9118,\n",
       " 'else': 2718,\n",
       " 'amazed': 323,\n",
       " 'lack': 5637,\n",
       " 'communication': 1703,\n",
       " 'fastest': 3074,\n",
       " 'achieve': 86,\n",
       " 'computer': 1755,\n",
       " 'kudos': 5626,\n",
       " 'usually': 10003,\n",
       " 'panic': 7077,\n",
       " 'status': 8954,\n",
       " 'ffl': 3127,\n",
       " 'group': 3744,\n",
       " 'actually': 110,\n",
       " 'hate': 3863,\n",
       " 'isi': 5306,\n",
       " 'thats': 9376,\n",
       " 'heard': 3894,\n",
       " 'bump': 1168,\n",
       " 'closer': 1588,\n",
       " 'understanding': 9837,\n",
       " 'situation': 8646,\n",
       " 'opened': 6910,\n",
       " 'premium': 7476,\n",
       " 'wifi': 10356,\n",
       " 'decent': 2156,\n",
       " 'slowfi': 8705,\n",
       " 'mileageplus': 6275,\n",
       " 'signup': 8610,\n",
       " 'page': 7058,\n",
       " 'jb': 5393,\n",
       " 'platinum': 7325,\n",
       " 'tired': 9511,\n",
       " 'overchging': 7012,\n",
       " 'bg': 892,\n",
       " 'herded': 3951,\n",
       " 'cattleslaughter': 1344,\n",
       " 'aircanada': 218,\n",
       " 'connecting': 1798,\n",
       " 'good': 3653,\n",
       " 'businessfirst': 1192,\n",
       " 'took': 9571,\n",
       " 'leg': 5739,\n",
       " 'route': 8187,\n",
       " 'jet': 5414,\n",
       " 'blue': 968,\n",
       " 'treat': 9663,\n",
       " 'properly': 7588,\n",
       " 'fan': 3057,\n",
       " 'brand': 1059,\n",
       " 'rock': 8163,\n",
       " 'iahhnl': 5004,\n",
       " 'sfo': 8489,\n",
       " 'reactive': 7754,\n",
       " 'proactive': 7533,\n",
       " 'literally': 5840,\n",
       " 'rather': 7736,\n",
       " 'mom': 6370,\n",
       " 'dr': 2552,\n",
       " 'appointment': 475,\n",
       " 'cun': 2012,\n",
       " 'advisory': 153,\n",
       " 'charged': 1417,\n",
       " 'reschedule': 8000,\n",
       " 'flighted': 3227,\n",
       " 'refusing': 7879,\n",
       " 'deal': 2141,\n",
       " 'changed': 1403,\n",
       " 'usairway': 9977,\n",
       " 'getting': 3581,\n",
       " 'iah': 5002,\n",
       " 'patient': 7136,\n",
       " 'luxurious': 5999,\n",
       " 'queue': 7670,\n",
       " 'eta': 2863,\n",
       " 'name': 6491,\n",
       " 'department': 2253,\n",
       " 'under': 9830,\n",
       " 'accountability': 78,\n",
       " 'website': 10248,\n",
       " 'seriously': 8461,\n",
       " 'center': 1374,\n",
       " 'tempting': 9319,\n",
       " 'sodone': 8768,\n",
       " 'realize': 7767,\n",
       " 'banning': 759,\n",
       " 'peanut': 7170,\n",
       " 'allergic': 279,\n",
       " 'ignores': 5041,\n",
       " 'pnut': 7367,\n",
       " 'oil': 6848,\n",
       " 'dust': 2621,\n",
       " 'previous': 7507,\n",
       " 'award': 674,\n",
       " 'policy': 7381,\n",
       " 'card': 1297,\n",
       " 'holder': 4013,\n",
       " 'seeing': 8408,\n",
       " 'chart': 1426,\n",
       " 'cause': 1347,\n",
       " 'suck': 9095,\n",
       " 'weasel': 10238,\n",
       " 'room': 8181,\n",
       " 'claiming': 1541,\n",
       " 'httptcoflcnnnusd': 4338,\n",
       " 'nonrefundable': 6687,\n",
       " 'hence': 3943,\n",
       " 'wrote': 10500,\n",
       " 'sense': 8444,\n",
       " 'nothanks': 6733,\n",
       " 'possible': 7415,\n",
       " 'flightlation': 3237,\n",
       " 'rectify': 7826,\n",
       " 'excited': 2927,\n",
       " 'saw': 8315,\n",
       " 'ionlyflyblue': 5285,\n",
       " 'learning': 5726,\n",
       " 'famous': 3055,\n",
       " 'social': 8763,\n",
       " 'medium': 6188,\n",
       " 'marketing': 6097,\n",
       " 'twitter': 9758,\n",
       " 'asset': 563,\n",
       " 'phdmama': 7225,\n",
       " 'believe': 847,\n",
       " 'receive': 7796,\n",
       " 'upcoming': 9945,\n",
       " 'true': 9696,\n",
       " 'jeffsmisek': 5407,\n",
       " 'robertfor': 8154,\n",
       " 'fiorettindward': 3172,\n",
       " 'garciachicago': 3532,\n",
       " 'faa': 3011,\n",
       " 'invest': 5269,\n",
       " 'miss': 6324,\n",
       " 'wk': 10398,\n",
       " 'httptcojvjzzaa': 4473,\n",
       " 'happening': 3831,\n",
       " 'wasn': 10201,\n",
       " 'working': 10443,\n",
       " 'wichita': 10352,\n",
       " 'fall': 3044,\n",
       " 'unknowledgeable': 9889,\n",
       " 'rt': 8198,\n",
       " 'httptcopkiqhi': 4655,\n",
       " 'yay': 10538,\n",
       " 'glitchy': 3618,\n",
       " 'tracking': 9613,\n",
       " 'destination': 2297,\n",
       " 'app': 453,\n",
       " 'tried': 9676,\n",
       " 'browser': 1123,\n",
       " 'continues': 1846,\n",
       " 'outbound': 6983,\n",
       " 'inbound': 5095,\n",
       " 'ewr': 2905,\n",
       " 'ready': 7760,\n",
       " 'dal': 2068,\n",
       " 'early': 2636,\n",
       " 'sofly': 8769,\n",
       " 'firststari': 3184,\n",
       " ...}"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the vocabulary of TfIdfVectorizer (in this case only for dataset where target variable is \"one hot\" encoded)\n",
    "T_vectorizer_d.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary of both vectorizers produce same output, which is expected since the same training data is used in both scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Fit and evaluate the model using both types of vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four models will be used, one for each set of trainning and test data generated in steps above, as described below:\n",
    "- rf_model_CV_d - random forest model which will be fitted with train data generated by count vectorizer where target is one hot encoded;\n",
    "- rf_model_CV_l - random forest model which will be fitted with train data generated by count vectorizer where target is label encoded;\n",
    "- rf_model_TV_d - random forest model which will be fitted with train data generated by tfidf vectorizer where target is one hot encoded; and\n",
    "- rf_model_TV_l - random forest model which will be fitted with train data generated by tfidf vectorizer where target is label encoded;\n",
    "\n",
    "Once the models are fitted, accuracy score will be extracted for all four models on both, train and test datasets, and finally confussion matrix will be generated at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countVectorizer\n",
    "#one_hot_encoded target\n",
    "\n",
    "#creating an insance of randomforest object that will be fitted (trainned) by data generated by countVectorizer \n",
    "rf_model_CV_d=RandomForestClassifier(random_state=7, n_estimators=10, n_jobs=4)\n",
    "#fitting the model (trainning)\n",
    "rf_model_CV_d=rf_model_CV_d.fit(x_train_features_countV_d, y_train_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfIdfVectorizer\n",
    "#one_hot_encoded target\n",
    "\n",
    "#creating an insance of randomforest object that will be fitted (trainned) by data generated by tfIdfVectorizer \n",
    "rf_model_TV_d=RandomForestClassifier(n_estimators=10, n_jobs=4, random_state=7)\n",
    "#fitting the model (trainning)\n",
    "rf_model_TV_d=rf_model_TV_d.fit(x_train_features_tfIdfV_d, y_train_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countVectorizer\n",
    "#label_encoded target\n",
    "\n",
    "#creating an insance of randomforest object that will be fitted (trainned) by data generated by countVectorizer \n",
    "rf_model_CV_l=RandomForestClassifier(random_state=7, n_estimators=10, n_jobs=4)\n",
    "#fitting the model (trainning)\n",
    "rf_model_CV_l=rf_model_CV_l.fit(x_train_features_countV_l, y_train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfIdfVectorizer\n",
    "#label_encoded target\n",
    "\n",
    "#creating an insance of randomforest object that will be fitted (trainned) by data generated by tfIdfVectorizer\n",
    "rf_model_TV_l=RandomForestClassifier(n_estimators=10, n_jobs=4)\n",
    "#fitting the model (trainning)\n",
    "rf_model_TV_l=rf_model_TV_l.fit(x_train_features_tfIdfV_l, y_train_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating accuracy score for each of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating accuracy score on train and test data\n",
    "#model trainned by data generated by countVectorizer\n",
    "#target variable was one_hot_encoded\n",
    "\n",
    "#score on train data\n",
    "rf_model_CV_score_train_d=rf_model_CV_d.score(x_train_features_countV, y_train)\n",
    "#score on test data\n",
    "rf_model_CV_score_test_d=rf_model_CV_d.score(x_test_features_countV, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of rf_model_CV_d on train data is 0.9627244340359095\n",
      "Accuracy score of rf_model_CV_d on test data is 0.6432149362477231\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score of rf_model_CV_d on train data is\", rf_model_CV_score_train_d)\n",
    "print(\"Accuracy score of rf_model_CV_d on test data is\",rf_model_CV_score_test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating accuracy score on train and test data\n",
    "#model trainned by data generated by TfIdfVectorizer\n",
    "#target variable was one_hot_encoded\n",
    "\n",
    "#score on train data\n",
    "rf_model_TV_score_train_d=rf_model_TV_d.score(x_train_features_tfIdfV_d, y_train)\n",
    "#score on test data\n",
    "rf_model_TV_score_test_d=rf_model_TV_d.score(x_test_features_tfIdfV_d, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of rf_model_TV_d on train data is 0.9666276346604216\n",
      "Accuracy score of rf_model_TV_d on test data is 0.639344262295082\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score of rf_model_TV_d on train data is\",rf_model_TV_score_train)\n",
    "print(\"Accuracy score of rf_model_TV_d on test data is\",rf_model_TV_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating accuracy score on train and test data\n",
    "#model trainned by data generated by CountVectorizer\n",
    "#target variable was label_encoded\n",
    "\n",
    "rf_model_CV_score_train_l=rf_model_CV_l.score(x_train_features_countV_l, y_train_l)\n",
    "#score on test data\n",
    "rf_model_CV_score_test_l=rf_model_CV_l.score(x_test_features_countV_l, y_test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of rf_model_CV_l on train data is 0.98467993754879\n",
      "Accuracy score of rf_model_CV_l on test data is 0.73816029143898\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score of rf_model_CV_l on train data is\", rf_model_CV_score_train_l)\n",
    "print(\"Accuracy score of rf_model_CV_l on test data is\",rf_model_CV_score_test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating accuracy score on train and test data\n",
    "#model trainned by data generated by TfIdfVectorizer\n",
    "#target variable was label_encoded\n",
    "\n",
    "rf_model_TV_score_train_l=rf_model_TV_l.score(x_train_features_tfIdfV_l, y_train_l)\n",
    "#score on test data\n",
    "rf_model_TV_score_test_l=rf_model_TV_l.score(x_test_features_tfIdfV_l, y_test_l)\n",
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of rf_model_TV_l on train data is 0.9758977361436377\n",
      "Accuracy score of rf_model_TV_ on test data is 0.7317850637522769\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score of rf_model_TV_l on train data is\",rf_model_TV_score_train_l)\n",
    "print(\"Accuracy score of rf_model_TV_ on test data is\",rf_model_TV_score_test_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the models are overfit which can be seen from the difference between accuracy achieved on train and test data. In addition, both models that were trained on datasets which have label encoded target varibale performed significantly better on test data. \n",
    "\n",
    "From the achieved accuracy, it is noticable that models trained on count vectorized data perfromed slightly better which was not expected, since there are lots of common words that have not been removed by preprocessing (e.g. no stop words removal was applied). \n",
    "\n",
    "In order to reduce overfit, radnom forest should be regulated with hyper parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "\n",
    "To calculate confusion matrix, confusion_matrix function from sklearn.metric is used. Function must be fed with predicted and true values.\n",
    "For predicted and true values where one hot encoded target varibale was use index of max value had to be given to confusion_matrix() function.\n",
    "It is worth noting that confusion matrix will be calculated on test data only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting classes where target variable was one hot encoded\n",
    "rf_model_CV_d_pred_test=rf_model_CV_d.predict(x_test_features_countV_d)\n",
    "rf_model_TV_d_pred_test=rf_model_TV_d.predict(x_test_features_tfIdfV_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting classes where target variable was label encoded\n",
    "rf_model_CV_l_pred_test=rf_model_CV_l.predict(x_test_features_countV_l)\n",
    "rf_model_TV_l_pred_test=rf_model_TV_l.predict(x_test_features_tfIdfV_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrices\n",
    "\n",
    "#target variable - one hot encoded\n",
    "#calculating confusion matrices\n",
    "cm_CV_d=confusion_matrix(y_test_d.values.argmax(axis=1), rf_model_CV_d.predict(x_test_features_countV_d).argmax(axis=1))\n",
    "cm_TV_d=confusion_matrix(y_test_d.values.argmax(axis=1), rf_model_TV_d.predict(x_test_features_tfIdfV_d).argmax(axis=1))\n",
    "\n",
    "#target variable - label encoded\n",
    "#calculating confusion matrices\n",
    "cm_CV_l=confusion_matrix(y_test_l, rf_model_CV_l.predict(x_test_features_countV_l))\n",
    "cm_TV_l=confusion_matrix(y_test_l, rf_model_TV_l.predict(x_test_features_tfIdfV_l))\n",
    "#cm=confusion_matrix(y_test.values.argmax(axis=1), rf_model_TV.predict(x_test_features_tfIdfV).argmax(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2671,   66,   16],\n",
       "       [ 645,  258,   27],\n",
       "       [ 414,   54,  241]], dtype=int64)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix for model trained with count vectorized data where target was one hot encoded variable\n",
    "cm_CV_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2686,   51,   16],\n",
       "       [ 662,  235,   33],\n",
       "       [ 458,   35,  216]], dtype=int64)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix for model trained with tf-idf vectorized data where target was one hot encoded variable\n",
    "cm_TV_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2592,  121,   40],\n",
       "       [ 511,  365,   54],\n",
       "       [ 326,   98,  285]], dtype=int64)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix for model trained with count vectorized data where target was label encoded variable\n",
    "cm_CV_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2601,  124,   28],\n",
       "       [ 533,  337,   60],\n",
       "       [ 341,  105,  263]], dtype=int64)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix for model trained with tf-idf vectorized data where target was label encoded variable\n",
    "cm_TV_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst=np.array([0,0,0])\n",
    "not(lst.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like all the difference between two distinct approaches with regarts to processing target variable lies in false negative sentiment, therefor the reason for such difference is explored in more details with code below.\n",
    "\n",
    "First, let's see are there any, and how many predictions are there where all three one hot encoded categories are predicted to be zero. This means there is no eligible class assigned to particular case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  900 cases where all three one hot encoded target varibales were predicted to be 0\n"
     ]
    }
   ],
   "source": [
    "#summ is variable which stores sum of such cases where all three targets were predicted 0 \n",
    "#in case where one hot encoded target is used\n",
    "summ=0\n",
    "\n",
    "#setting index variable to 0\n",
    "index=0\n",
    "#index_list will be used to store indexes of cases described above\n",
    "index_list=[]\n",
    "#looping through predictions\n",
    "for lst in rf_model_CV_d_pred_test:\n",
    "    #checking if all three predicted values a re equal to 0 - not(any()) is used to negate result of any()\n",
    "    if not(lst.any()):\n",
    "        #if it is the case - summ is added by 1\n",
    "        summ+=1\n",
    "        #index of such case is recorded in index_list\n",
    "        index_list.append(index)\n",
    "    index+=1\n",
    "print (\"There are \",summ,\"cases where all three one hot encoded target varibales were predicted to be 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing one of such cases\n",
    "rf_model_CV_d_pred_test[index_list[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the result of argmax in such cases\n",
    "rf_model_CV_d_pred_test[index_list[0]].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion for CM\n",
    "\n",
    "Confusion matrices of models trained on data with one-hot encoded target variable shows higher amount of false negative. The reason for that should be looked in argmax function which returns index of max value in list of three values for each predicted set of values (there are three output variables). Once all three are incorrectly predicted as 0, argmax will return index of first one, which belongs to negative sentiment, hence boosting false negative.\n",
    "In general, all confusion matrices shows highest values along diagonal, whixh was expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularized model with lower number of features\n",
    "\n",
    "In order to reduce overfit problem evident in all of the models, regularized random forest  model will be created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the number of features are reduced in training data by setting hyper parameter max_features of CountVectorizer to avoid course of dimensionality. Code below explore number of features if such paramtere is not set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10579"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of words(features) - obtained as len of list of keys of vocabulary\n",
    "len(C_vectorizer_l.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for target label encoded\n",
    "\n",
    "#creating vectorizer - C in name means count, l at the end means label encoded target variable\n",
    "C_vectorizer_l_reg=CountVectorizer(max_features=500)\n",
    "\n",
    "#vectorizer is fitted with trainning data\n",
    "C_vectorizer_l_reg.fit(x_train_l)\n",
    "\n",
    "#transform is applied on both, trainning and test data\n",
    "x_train_features_countV_l_reg=C_vectorizer_l.transform(x_train_l)\n",
    "x_test_features_countV_l_reg=C_vectorizer_l.transform(x_test_l)\n",
    "\n",
    "x_train_features_countV_l_reg=x_train_features_countV_l_reg.toarray()\n",
    "x_test_features_countV_l_reg=x_test_features_countV_l_reg.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verifying the number of features once it has been reduced\n",
    "len(C_vectorizer_l_reg.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model with number of estimators and max_features to be used while creating each individual estimators\n",
    "rf_model_CV_l_reg=RandomForestClassifier(n_estimators = 500, random_state=7,max_features=100, max_depth=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainning the model\n",
    "rf_model_CV_l_reg=rf_model_CV_l_reg.fit(x_train_features_countV_l_reg, y_train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of model on training data\n",
    "rf_model_CV_score_train_l_reg=rf_model_CV_l_reg.score(x_train_features_countV_l_reg, y_train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of model on test data\n",
    "rf_model_CV_score_test_l_reg=rf_model_CV_l_reg.score(x_test_features_countV_l_reg, y_test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of rf_model_CV_l_reg on train data is 0.6834504293520687\n",
      "Accuracy score of rf_model_CV_l_reg on test data is 0.6520947176684881\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score of rf_model_CV_l_reg on train data is\", rf_model_CV_score_train_l_reg)\n",
    "print(\"Accuracy score of rf_model_CV_l_reg on test data is\",rf_model_CV_score_test_l_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code above explore possibilities to regularize radnom forest classifier to reduce overfit problem, but to increase accuracy of a model. The idea is to generate more rather poor estimators, but robust ensemble of such poor estimators. Each estimator is pruned with max_depth. Max_features in combination with number of estimators selected (100 and 500 respectively) gives a good chance for all features to be used in estimators. As a result overfit has been reduced, however such reduction was payed by lower accuracy. Probably some other ML or DNN technique should be tested as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Summarize your understanding of the application of Various Pre-processing and Vectorization and performance of your model on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of all text preprocessing steps are to get more clear (valuable) set of features to be used for model.\n",
    "Html tag removal is apllied to remove html tags that might be common to whole corpus, rendering it as redundant, carying no or little information. \n",
    "Tokenization tokenized text for lemmatization.\n",
    "Removal of numbers has the same goal as removal of html tags, while conversion to lower case and removal of special characters and punctuations have goal of reducing number of possible features - e.g. \"Word\" and \"word\" would be two different features.\n",
    "\n",
    "Tf-Idf Vectorizer is expected to give better results (because of it's ability to better extract more important features in vectors), however, it showed slightly lower perfomance (the model trained by such dataset showed lower perfomance). \n",
    "\n",
    "It has been noticed once the countVectorizer was limited with max_features, the accuracy score on both, test and train data increased. \n",
    "\n",
    "All of random forest models showed significant overfit problem, so all of them required some sort of regularization. Models trained with label encoded target variable showed significantly better performance on test data (~10% better accuracy score for both vectorization principles).\n",
    "\n",
    "It was interesting to see how confusion matrices are wrongly calculated indicating problems of no class identified in some cases where one hot encoded target variables were used (this has been explained in details in part related to confusion matrices)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Overall notebook should have\n",
    "\n",
    "## a. Well commented code\n",
    "Code has been comented\n",
    "\n",
    "## b. Structure and flow\n",
    "This notebook is structured to fit all the tasks in sequntial manner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
